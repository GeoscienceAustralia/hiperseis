{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porting Ammon's RF deconvolution code from Fortran to Python\n",
    "\n",
    "Based on reference code downloaded from http://eqseis.geosc.psu.edu/~cammon/HTML/RftnDocs/thecodes01.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import obspy\n",
    "import scipy\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcorrelate(f, g, n, MAXPTS, dt): # n and MAXPTS probably redundant\n",
    "    \"\"\"\n",
    "    correlation routine - correlates f and g and replaces the \n",
    "      g with the cross-correlation the value is normalized\n",
    "      by the zero-lag autocorrelation of g\n",
    "\n",
    "    n = len(g), should be same as len(f)\n",
    "    \n",
    "    Returns result in g\n",
    "    \"\"\"\n",
    "#     real f(MAXPTS), g(MAXPTS), c(8192)\n",
    "    c = np.zeros(MAXPTS)\n",
    "\n",
    "    # compute the zero-lag autocorrelation of g\n",
    "    sum0 = dt*np.dot(g, g)\n",
    "\n",
    "    n2 = 1\n",
    "    while n2 < n:\n",
    "        n2 = n2 * 2\n",
    "\n",
    "    # Use the Numerical Recipes routine to compute the cross correlation\n",
    "#     call correl(f, g, n2, c) # output ends up in c\n",
    "    c = scipy.signal.correlate(f, g, mode='same')\n",
    "    # Zero or positive lags in result (using sign convention of correl)\n",
    "    # are in elements [n/2:n] of c. Roll result to match layout out output\n",
    "    # of correl.\n",
    "    c = np.roll(c, -n//2)\n",
    "\n",
    "    temp = dt / sum0\n",
    "    # **Note**: this is intended to change values in g in-place up to n2,\n",
    "    # i.e. re-using g as output array.\n",
    "    g[0:n2] = c[0:n2] * temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getres(x, y, n):\n",
    "    \"\"\"\n",
    "    get the residual between x and y\n",
    "    \n",
    "    n = len(x), len(y)\n",
    "    \"\"\"\n",
    "#     real x(n), y(n), r(n), sumsq\n",
    "\n",
    "    r = x - y\n",
    "    sumsq = np.dot(r, r)\n",
    "\n",
    "    return r, sumsq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfilter(x, gwidth_factor, n, dt):\n",
    "    \"\"\"\n",
    "    convolve a function with a unit-area Gaussian filter.\n",
    "    \"\"\"\n",
    "#     real x(n), two_pi, gauss, d_omega, omega\n",
    "#     real gwidth, gwidth_factor, sum\n",
    "\n",
    "    two_pi = 2 * np.pi\n",
    "\n",
    "    n2 = 1\n",
    "    while n2 < n:\n",
    "        n2 = n2 * 2\n",
    "\n",
    "    halfpts = n2 // 2\n",
    "\n",
    "#     call realft(x,halfpts,forward)\n",
    "    fft_x = np.fft.rfft(x, halfpts)  # complex array\n",
    "\n",
    "    df = 1.0 / (float(n2) * dt)\n",
    "    d_omega = two_pi * df\n",
    "    gwidth = 4.0*gwidth_factor*gwidth_factor\n",
    "\n",
    "    omega = np.arange(halfpts)*d_omega\n",
    "    gauss = np.exp(-omega*omega/gwidth)\n",
    "    fft_x = fft_x * gauss\n",
    "    \n",
    "#     call realft(x,halfpts,inverse)\n",
    "    x_filt = np.fft.irfft(fft_x, halfpts)  # real_array\n",
    "\n",
    "    scalefactor = dt * (2 * df)\n",
    "    x_filt = x_filt*scalefactor\n",
    "\n",
    "    return x_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Ammon's convolve function, just replace with\n",
    "# x = scipy.signal.convolve(x, y, mode='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phs_shift(x, theshift, n, dt):\n",
    "    \"\"\"\n",
    "    phase shifts a signal\n",
    "    \"\"\"\n",
    "#     real x(n), pi, two_pi, theshift, d_omega, omega\n",
    "\n",
    "    two_pi = 2 * np.pi\n",
    "\n",
    "    n2 = 1\n",
    "    while n2 < n:\n",
    "        n2 = n2 * 2\n",
    "\n",
    "    halfpts = n2 // 2\n",
    "\n",
    "#     call realft(x, halfpts, forward)\n",
    "    fft_x = np.fft.rfft(x, halfpts)  # complex array\n",
    "\n",
    "    df = 1 / (float(n2) * dt)\n",
    "    d_omega = two_pi * df\n",
    "\n",
    "    omega = np.arange(halfpts)*d_omega\n",
    "    # Copied from Ammon, but weird(?).\n",
    "    # Shouldn't it just be spectral_shift = np.exp(theshift*1j) ?? (drop the omega)\n",
    "    spectral_shift = np.exp(omega*theshift*1j)\n",
    "    ffx_x = ffx_t * spectral_shift\n",
    "\n",
    "#     call realft(x,halfpts,inverse)\n",
    "    x_shifted = np.fft.irfft(fft_x, halfpts)  # real_array\n",
    "\n",
    "    scalefactor = dt * (2 * df)\n",
    "    x_shifted = x_shifted * scalefactor\n",
    "\n",
    "    return x_shifted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decon(amps, shifts, nshifts, p, n, gwidth, dt):\n",
    "    \"\"\"\n",
    "    compute the predicted time series from a set of\n",
    "    amplitudes and shifts\n",
    "    \"\"\"\n",
    "#     real p(n), amps(nshifts)\n",
    "#     integer shifts(nshifts)\n",
    "#     integer i, n, nshifts\n",
    "      \n",
    "    p[shifts] = p[shifts] + amps\n",
    "\n",
    "    x = gfilter(p, gwidth, n, dt)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterdeconfd():\n",
    "    MAXPTS = 8192\n",
    "    MAXG = 200\n",
    "    f = np.zeros(MAXPTS)\n",
    "    g = np.zeros(MAXPTS)\n",
    "    p = np.zeros(MAXPTS)\n",
    "#     r = np.zeros(MAXPTS)\n",
    "    amps = np.zeros(MAXG)\n",
    "    shifts = np.zeros(MAXG).astype(int)\n",
    "    resfile = ' '*12\n",
    "    filename = ' '*12\n",
    "\n",
    "    stdin = 5\n",
    "    stdout = 6\n",
    "    ounit = 9\n",
    "    inunit = 10\n",
    "#     forward = 1\n",
    "#     inverse = -1\n",
    "    lpositive = False\n",
    "    verbose = False\n",
    "    gwidth = 2.5\n",
    "\n",
    "    print('\\n')\n",
    "    print('Program iterdeconfd - Version 1.04, 1997-98')\n",
    "    print('Chuck Ammon, Saint Louis University')\n",
    "    print('\\n')\n",
    "\n",
    "    # read in the names of the input files\n",
    "      \n",
    "    numerator = input('What is the numerator file?')\n",
    "    denominator = input('What is the denominator file?')\n",
    "    maxbumps = int(input('What is the max number of iterations?'))\n",
    "\n",
    "    if (maxbumps > MAXG):\n",
    "        print('Maximum Number of bumps is %d' % MAXG)\n",
    "        maxbumps = 200\n",
    "    # end if\n",
    "    theshift = float(input('What is the phase shift (secs) for the output?'))\n",
    "    tol = float(input('What is minimum percent error increase to accept?'))\n",
    "    gwidth = float(input('What is is the Gaussian filter width factor?'))\n",
    "    idum = int(input('Allow negative pulses? (1->y, 0->no)'))\n",
    "    if (idum == 1):\n",
    "        lpositive = False\n",
    "    else:\n",
    "        lpositive = True\n",
    "    # end if \n",
    "\n",
    "    idum = int(input('Minimal (0) or verbose output(1)?'))\n",
    "    if (idum == 0):\n",
    "        verbose = False\n",
    "    else:\n",
    "        verbose = True\n",
    "    # end if\n",
    "\n",
    "    # *************************************************************************\n",
    "#     call rsac1(numerator, f, npts, beg, delta, MAXPTS, nerr)\n",
    "    f = obspy.read(numerator)\n",
    "    npts = len(f)\n",
    "\n",
    "#     call rsac1(denominator,g,nptsd,b,dt,MAXPTS,nerr)\n",
    "    g = obspy.read(denominator)\n",
    "    nptsd = len(g)\n",
    "    dt = 1.0/g[0].meta.sampling_rate  # grab dt from first trace\n",
    "\n",
    "    # *************************************************************************\n",
    "    # Find the next power of two greater than the data\n",
    "    #  dimensions - use the numerator, zero pad\n",
    "    n = 1\n",
    "    while n < npts:\n",
    "        n = n * 2\n",
    "\n",
    "    if (n > MAXPTS):\n",
    "        print('Too many points needed.')\n",
    "        print('n = %d' % n)\n",
    "        exit(1)\n",
    "    # end if\n",
    "\n",
    "    # *************************************************************************\n",
    "    # zero-pad the data\n",
    "    npts = n\n",
    "\n",
    "    # *************************************************************************\n",
    "    # FINISHED READING THE FILES\n",
    "    # *************************************************************************\n",
    "\n",
    "    # Now begin the cross-correlation procedure\n",
    "\n",
    "    # Put the filter in the signals\n",
    "    f = gfilter(f, gwidth, npts, dt)\n",
    "    g = gfilter(g, gwidth, npts, dt)\n",
    "    # Buffering to disk for later read-back?\n",
    "    f.write('numerator', format='sac')\n",
    "    f.write('observed', format='sac')\n",
    "    g.write('denominator', format='sac')\n",
    "\n",
    "    # compute the power in the \"numerator\" for error scaling\n",
    "    power = np.dot(f, f)\n",
    "\n",
    "    # correlate the signals\n",
    "    fcorrelate(f, g, npts, MAXPTS, dt)\n",
    "#     g.write('ccor0', format='sac')\n",
    "\n",
    "    # find the peak in the correlation\n",
    "    maxlag = npts//2\n",
    "    print('The maximum spike delay is %g' % float(maxlag) * dt)\n",
    "\n",
    "    g_prime = g[0:maxlag]\n",
    "    if (lpositive):\n",
    "        shifts[0] = np.argmax(g_prime)\n",
    "        amps[0] = g_prime[shifts[0]]\n",
    "    else:\n",
    "        g_abs = np.abs(g_prime)\n",
    "        shifts[0] = np.argmax(g_abs)\n",
    "        amps[0] = g_abs[shifts[0]]\n",
    "    # end if\n",
    "    amps[0] = amps[0] / dt\n",
    "\n",
    "    nshifts = 0\n",
    "\n",
    "    # read in the signals again  # TODO: rationalize the I/O in this routine\n",
    "#     call rsac1(numerator,f,ndummy,beg,delta,MAXPTS,nerr)\n",
    "    f = obspy.read(numerator)\n",
    "#     call rsac1(denominator,g,ndummy,b,dt,MAXPTS,nerr)\n",
    "    g = obspy.read(denominator)\n",
    "    dt = 1.0/g[0].meta.sampling_rate  # grab dt from first trace\n",
    "\n",
    "    # compute the predicted deconvolution result\n",
    "    p = np.zeros(MAXPTS)\n",
    "    p = build_decon(amps, shifts, nshifts, p, npts, gwidth, dt)\n",
    "    if (verbose):\n",
    "        p_shifted = phs_shift(p, theshift, npts, dt)\n",
    "        p_shifted.write('d000', format='sac')\n",
    "    # end if\n",
    "\n",
    "    # convolve the prediction with the denominator signal\n",
    "#     call convolve(p,g,npts,dt)\n",
    "    p = scipy.signal.convolve(p, g, mode='same')  # need to check dt scaling here...\n",
    "\n",
    "    if (verbose):\n",
    "        p.write('p000', format='sac')\n",
    "    # end if\n",
    "\n",
    "    # filter the signals\n",
    "    f = gfilter(f, gwidth, npts, dt)\n",
    "    g = gfilter(g, gwidth, npts, dt)\n",
    "\n",
    "    if (verbose):\n",
    "        resfile = 'r%03d' % 0\n",
    "        f.write(resfile, format='sac')\n",
    "    # end if\n",
    "\n",
    "    # compute the residual (initial error is 1.0)\n",
    "    r, sumsq_ip1 = getres(f, p, npts)\n",
    "\n",
    "    sumsq_i = 1.0\n",
    "    sumsq_ip1 = sumsq_ip1 / power\n",
    "    d_error = 100*(sumsq_i - sumsq_ip1)\n",
    "\n",
    "    resfile = 'r%03d' % 1\n",
    "    if (verbose):\n",
    "        r.write(resfile, format='sac')\n",
    "    # end if\n",
    "\n",
    "    print('%9s %s' % ('File', 'Spike amplitude   Spike delay   Misfit   Improvement'))\n",
    "    print('%10s  %16.9e  %10.3f   %7.2f%%   %9.4f%%' % (resfile, dt*amps[0], (shifts[0]-1)*dt, 100*sumsq_ip1, d_error))\n",
    "\n",
    "    # *************************************************************************\n",
    "    while (d_error > tol) and (nshifts < maxbumps):\n",
    "\n",
    "        nshifts = nshifts + 1\n",
    "        sumsq_i = sumsq_ip1\n",
    "\n",
    "#         g = np.zeros(MAXPTS)\n",
    "        g = obspy.read(denominator, format='sac')\n",
    "\n",
    "        g = gfilter(g, gwidth, npts, dt)\n",
    "        fcorrelate(r, g, npts, MAXPTS, dt)\n",
    "\n",
    "        g_prime = g[0:maxlag]\n",
    "        if (lpositive):\n",
    "            shifts[nshifts] = np.argmax(g_prime)\n",
    "            amps[nshifts] = g_prime[shifts[nshifts]]\n",
    "        else:\n",
    "            g_abs = np.abs(g_prime)\n",
    "            shifts[nshifts] = np.argmax(g_abs)\n",
    "            amps[nshifts] = g_abs[shifts[nshifts]]\n",
    "        # end if\n",
    "        amps(nshifts) = amps(nshifts) / dt\n",
    "\n",
    "        p = np.zeros(MAXPTS)\n",
    "        p = build_decon(amps, shifts, nshifts, p, npts, gwidth, dt)\n",
    "        if (verbose):\n",
    "            filename = '(d%03d)' % nshifts\n",
    "            p_shifted = phs_shift(p, theshift, npts, dt)\n",
    "#             wsac1(filename, p, npts, -theshift, dt, nerr)\n",
    "            p_shifted.write(filename, format='sac')\n",
    "        # end if\n",
    "\n",
    "#         g = np.zeros(MAXPTS)\n",
    "        g = obspy.read(denominator, format='sac')\n",
    "        p = scipy.signal.convolve(p, g, mode='same')  # need to check dt scaling here...\n",
    "        if (verbose):\n",
    "            filename = '(p%03d)' % nshifts\n",
    "            p.write(filename, format='sac')\n",
    "        end if\n",
    "\n",
    "#         f = np.zeros(MAXPTS)\n",
    "        f = obspy.read(numerator)\n",
    "        f = gfilter(f, gwidth, npts, dt)\n",
    "        r, sumsq_ip1 = getres(f, p, npts)\n",
    "        \n",
    "        sumsq_ip1 = sumsq_ip1/ power\n",
    "        resfile = '(r%03d)' % nshifts\n",
    "        if (verbose):\n",
    "            r.write(resfile, format='sac')\n",
    "        # end if\n",
    "        d_error = 100*(sumsq_i - sumsq_ip1)\n",
    "\n",
    "        print('%10s  %16.9e  %10.3f   %7.2f%%   %9.4f%%' % (resfile,\n",
    "            dt*amps[nshifts], (shifts[nshifts]-1)*dt, 100*sumsq_ip1, d_error))\n",
    "    # enddo\n",
    "\n",
    "    # *************************************************************************\n",
    "\n",
    "    print('Last Error Change = %9.4f%%' % d_error)\n",
    "\n",
    "    # if the last change made no difference, drop it\n",
    "    fit = 100 - 100*sumsq_ip1\n",
    "    if (d_error <= tol):\n",
    "        nshifts = nshifts - 1\n",
    "        fit = 100 - 100*sumsq_i\n",
    "        print('Hit the min improvement tolerance - halting.')\n",
    "    # end if\n",
    "\n",
    "    if (nbumps >= maxbumps):\n",
    "        print('Hit the max number of bumps - halting.')\n",
    "    # end if\n",
    "\n",
    "    print('Number of bumps in final result: %d' % nshifts)\n",
    "    print('The final deconvolution reproduces %6.1f%% of the signal.' % fit)\n",
    "\n",
    "    # *************************************************************************\n",
    "\n",
    "    # compute the final prediction\n",
    "    p = np.zeros(MAXPTS)\n",
    "    p = build_decon(amps, shifts, nshifts, p, npts, gwidth, dt)\n",
    "\n",
    "#     g = np.zeros(MAXPTS)\n",
    "    g = obspy.read(denominator, format='sac')\n",
    "    p = scipy.signal.convolve(p, g, mode='same')  # need to check dt scaling here...\n",
    "    p.write('predicted', format='sac')\n",
    "    g = np.zeros(MAXPTS)\n",
    "\n",
    "    # write out the answer\n",
    "    p = np.zeros(MAXPTS)\n",
    "    p = build_decon(amps, shifts, nshifts, p, npts, gwidth, dt)\n",
    "    p_shifted = phs_shift(p, theshift, npts, dt)\n",
    "\n",
    "    # This rigmarole is to do with writing detailed SAC header information to file\n",
    "#       call newhdr\n",
    "#       call rsac1(numerator, g, ndummy, b, dt, MAXPTS, nerr)\n",
    "#       call setnhv('NPTS',npts,nerr)\n",
    "#       call setfhv('B',-theshift,nerr)\n",
    "#       theend = -thshift + (npts-1)*dt\n",
    "#       call setfhv('E',theend,nerr)\n",
    "#       call setnhv('NZSEC',-12345,nerr)\n",
    "#       call setfhv('USER0',gwidth,nerr)\n",
    "# c     call setkhv('KUSER0','Rftn',nerr)\n",
    "# c     call setkhv('KUSER1','IT_DECON',nerr)\n",
    "#       call wsac0('decon.out',xdummy,p,nerr)\n",
    "    p_shifted.write('decon.out', format='sac')\n",
    "\n",
    "    # write out the gaussian filter\n",
    "    if (verbose):\n",
    "#         call newhdr\n",
    "#         call zero(p,MAXPTS)\n",
    "#         p(1) = 1 / dt\n",
    "#         call phs_shift(p,theshift,npts,dt)      \n",
    "#         call gfilter(p,gwidth,npts,dt)\n",
    "#         call wsac1('thefilter',p,npts,beg,dt,nerr)\n",
    "        p = np.zeros(MAXPTS)\n",
    "        p[0] = 1.0 / dt\n",
    "        p_shifted = phs_shift(p, theshift, npts, dt)\n",
    "        p = gfilter(p_shifted, gwidth, npts, dt)\n",
    "        p.write('thefilter', format='sac')\n",
    "    # end if\n",
    "\n",
    "# end func\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
