{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import rf\n",
    "import rf.imaging\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import obspy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in interactive widgets capability. See https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismic.receiver_fn.rf_util as rf_util\n",
    "import seismic.receiver_fn.rf_plot_utils as rf_plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose RF type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_type = 'ZRT_td'\n",
    "# rf_type = 'ZRT_fd'\n",
    "# rf_type = 'LQT_td'\n",
    "rf_type = 'LQT_fd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose training station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_station = 'BT23'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = r\"..\\DATA\\OA_rfs_20170911T000036-20181128T230620_{}_rev5_qual.h5\".format(rf_type)\n",
    "oa_all = rf_util.read_h5_rf(src_file, network='OA', station=training_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = rf_util.rf_to_dict(oa_all)\n",
    "oa_trainer = db[training_station]\n",
    "if rf_type[0:3] == 'ZRT':\n",
    "    prospective_channels = ['HHR', 'BHR']\n",
    "elif rf_type[0:3] == 'LQT':\n",
    "    prospective_channels = ['HHQ', 'BHQ']\n",
    "else:\n",
    "    prospective_channels = []\n",
    "# end if\n",
    "channel = None\n",
    "for c in prospective_channels:\n",
    "    if c in oa_trainer:\n",
    "        channel = c\n",
    "        break\n",
    "# end for\n",
    "print(\"Selected channel: {}\".format(channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oa_trainer[channel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional statistics for prediction of trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_util.compute_extra_rf_stats(oa_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display ranges of metadata and quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_series(traces, field):\n",
    "    x = [tr.stats.get(field) for tr in traces]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata and quality data on all traces for the target channel\n",
    "channel_data = oa_trainer[channel]\n",
    "\n",
    "snr = get_metadata_series(channel_data, 'snr')\n",
    "entropy = get_metadata_series(channel_data, 'entropy')\n",
    "coherence = get_metadata_series(channel_data, 'max_coherence')\n",
    "distance = get_metadata_series(channel_data, 'distance')\n",
    "inclination = get_metadata_series(channel_data, 'inclination')\n",
    "magnitude = get_metadata_series(channel_data, 'event_magnitude')\n",
    "depth = get_metadata_series(channel_data, 'event_depth')\n",
    "rf_group = get_metadata_series(channel_data, 'rf_group')\n",
    "# Replace no-group group IDs with '-1'\n",
    "rf_group = [g if g is not None else -1 for g in rf_group]\n",
    "amax = get_metadata_series(channel_data, 'amax')\n",
    "# Extra metrics\n",
    "amp_20pc = get_metadata_series(channel_data, 'amp_20pc')\n",
    "amp_80pc = get_metadata_series(channel_data, 'amp_80pc')\n",
    "mean_cplx_amp = get_metadata_series(channel_data, 'mean_cplx_amp')\n",
    "rms_amp = get_metadata_series(channel_data, 'rms_amp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of data and labels to use to plot histogram distributions\n",
    "dist_array = [(snr, \"SNR\"), (entropy, \"Entropy\"), (coherence, \"Coherence\"), (distance, \"Distance\"),\n",
    "              (inclination, \"Inclination\"), (magnitude, \"Magnitude\"), (amax, \"Max amplitude\"), (amp_20pc, \"Amplitude 20th perc.\"),\n",
    "              (amp_80pc, \"Amplitude 80th perc.\"), (mean_cplx_amp, \"Mean amplitude\"), (rms_amp, \"RMS amplitude\"), (rf_group, \"Group ID\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of metrics\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(3,4,1)\n",
    "for i, (data, name) in enumerate(dist_array):\n",
    "    ax = plt.subplot(3, 4, i + 1)\n",
    "#     plt.hist(data, bins=20)\n",
    "    sns.distplot(data, bins=20, ax=ax)\n",
    "    plt.title(name + \" distribution\", y=0.88, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine co-plots to look for discriminating variables\n",
    "df = pd.DataFrame.from_dict({\"SNR\": snr, \"Entropy\": entropy, \"Coherence\": coherence, \"Max_amp\": amax,\n",
    "                             \"Amp_20pc\": amp_20pc, \"Amp_80pc\": amp_80pc, \"RMS_amp\": rms_amp, \"Mean_amp\": mean_cplx_amp,\n",
    "                             \"Magnitude\": \">=6\", \"Distance\": \">=60\", \"Depth\": \">=80km\",\n",
    "                             \"Inclination\": \">=20\", \"Group_id\": rf_group,\n",
    "                             \"Quality\": \"unknown\"})\n",
    "df.loc[(np.array(magnitude) < 6.0), \"Magnitude\"] = \"<6\"\n",
    "df.loc[(np.array(distance) < 60.0), \"Distance\"] = \"<60\"\n",
    "df.loc[(np.array(inclination) < 20.0), \"Inclination\"] = \"<20\"\n",
    "df.loc[(np.array(depth) < 80.0), \"Depth\"] = \"<80km\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_file = training_station + \"_quality_labels_{}.csv\".format(rf_type)\n",
    "if os.path.isfile(qual_file):\n",
    "    loaded_quality = pd.read_csv(qual_file, index_col=0, header=None)\n",
    "    df['Quality'] = loaded_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interactive widget to manually label the quality of the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quality guide:\")\n",
    "print(\"'a' = low signal before onset, higher signal after onset with some multiples visible\")\n",
    "print(\"'b' = signal similar before and after onset, cannot make out multiples with much confidence\")\n",
    "print(\"Create labels by entering 10 character string of 'a's and 'b's according to quality, ordered from bottom to top trace.\")\n",
    "# Create labels for quality. Note that rf plots are numbered from the bottom up, whereas the Pandas table is displayed ordered from the top down.\n",
    "quality_updated = False\n",
    "for i in range(0, len(df), 10):\n",
    "    existing_qual = df['Quality'].iloc[i:i+10].values\n",
    "    if not 'unknown' in existing_qual:\n",
    "        continue\n",
    "    rf_slice = rf.RFStream(channel_data[i:i+10])\n",
    "    rf_plot_utils.plot_rf_stack(rf_slice, trace_height=0.4)\n",
    "    plt.show()\n",
    "    get_labels = ''\n",
    "    quit = False\n",
    "    while len(get_labels) != len(rf_slice):\n",
    "        get_labels = input(\"Enter labels: \")\n",
    "        if get_labels.lower() == 'quit':\n",
    "            quit = True\n",
    "            break\n",
    "        if len(get_labels) != len(rf_slice):\n",
    "            print(\"Wrong number of labels, try again!\")\n",
    "    if quit:\n",
    "        break\n",
    "    for j, qual in enumerate(get_labels):\n",
    "        df['Quality'].iloc[i+j] = qual\n",
    "    quality_updated = True\n",
    "    display(df.iloc[i:i+10])\n",
    "\n",
    "if quality_updated:\n",
    "    df['Quality'].to_csv(qual_file)\n",
    "else:\n",
    "    display(df.sample(20, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign quality category to trace metadata\n",
    "for i, tr in enumerate(channel_data):\n",
    "    tr.stats.quality = df['Quality'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot labelled data to find metrics to discriminate trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_metrics = [\"SNR\", \"Entropy\", \"Coherence\", \"Max_amp\", \"Amp_20pc\", \"Amp_80pc\", \"RMS_amp\", \"Mean_amp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_pairplot(df, plot_vars, hue_by='Quality', title=''):\n",
    "    hue_order = None\n",
    "    if hue_by == 'Quality' or hue_by == 'Prediction':\n",
    "        hue_order = ['unknown', 'b', 'a'] if 'unknown' in df['Quality'] else ['b', 'a']\n",
    "    sns.pairplot(df, hue=hue_by, hue_order=hue_order, vars=plot_vars)\n",
    "    plt.suptitle(title, y=1.01, fontsize=20)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def _metrics_pairplot(hue_by=['Quality', 'Magnitude', 'Distance', 'Depth', 'Inclination', 'Group_id']):\n",
    "    metrics_pairplot(df, stats_metrics, hue_by, title=\"Pairwise quality metrics scatter plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pairplot(df, plot_vars=stats_metrics, hue_by='Quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network classifier to discriminate quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use simple stats for feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_quality_mask = (df['Quality'] != 'unknown')\n",
    "X = df.loc[known_quality_mask, stats_metrics]\n",
    "X[np.isnan(X)] = 0\n",
    "y = df['Quality'].loc[known_quality_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_transformed = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This perceptron network has been simplified back to the bare bone so that it corresponds to a linear predictor,\n",
    "# as higher order complexity and non-linear activation functions gave no improvement in accuracy.\n",
    "clf_simple = MLPClassifier(solver='lbfgs', alpha=1e-4, max_iter=1000, activation='identity',\n",
    "                           hidden_layer_sizes=(4,), random_state=3772, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to tune hyperparameters\n",
    "scores = cross_val_score(clf_simple, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With tuned hyperparameters, train on full training set.\n",
    "clf_simple.fit(X_train, y_train)\n",
    "print(\"Final loss: %0.4f\" % clf_simple.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = clf_simple.score(X_test, y_test)\n",
    "print(\"Final accuracy: %0.3f\" % final_score)\n",
    "# We get decent performance with a trivial network (1 neuron) with trivial activation f(x) = x,\n",
    "# which means that simply a linear combination of feature vector is sufficient to determine\n",
    "# classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply quality classifier to whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df[stats_metrics]\n",
    "X_full[np.isnan(X_full)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prediction = clf_simple.predict(X_full)\n",
    "confidences = clf_simple.predict_proba(X_full)\n",
    "confidence_index = np.zeros(full_prediction.shape).astype(np.int)\n",
    "confidence_index[(full_prediction == 'b')] = 1\n",
    "df['Prediction'] = full_prediction\n",
    "df['Confidence'] = confidences[range(confidence_index.size), confidence_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the order of metrics so that weightings can be interpreted in relation to metrics\n",
    "print(stats_metrics)\n",
    "# Display the coefficients of the trained classifier\n",
    "print(\"Hidden layer:\")\n",
    "print(\"  weightings: {}\".format(clf_simple.coefs_[0].T[0]))\n",
    "print(\"        bias: {}\".format(clf_simple.intercepts_[0]))\n",
    "A0 = clf_simple.coefs_[0].T[0]\n",
    "b0 = clf_simple.intercepts_[0][0]\n",
    "\n",
    "print(\"Output layer:\")\n",
    "print(\"  weightings: {}\".format(clf_simple.coefs_[1][0]))\n",
    "print(\"        bias: {}\".format(clf_simple.intercepts_[1]))\n",
    "A1 = clf_simple.coefs_[1][0][0]\n",
    "b1 = clf_simple.intercepts_[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This formulation of prediction metric only applies to single neuron with linear activation function\n",
    "prediction_metric = A1*(np.matmul(X_full.values, A0) + b0) + b1\n",
    "df['Prediction metric'] = prediction_metric\n",
    "df.sample(20, random_state=3772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot whole prediction dataset\n",
    "@interact_manual\n",
    "def _metrics_pairplot(hue_by=['Prediction', 'Quality']):\n",
    "    metrics_pairplot(df, stats_metrics, hue_by, title=\"Pairwise predicted quality scatter plot - full data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction just on test dataset\n",
    "@interact_manual\n",
    "def _metrics_pairplot(hue_by=['Prediction', 'Quality']):\n",
    "    metrics_pairplot(df.iloc[sorted(X_test.index)], stats_metrics, hue_by, title=\"Pairwise predicted quality scatter plot - test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix and verify how to compute accuracy from it.\n",
    "cm = confusion_matrix(df.loc[known_quality_mask, 'Quality'], df.loc[known_quality_mask, 'Prediction'], labels=['b', 'a'])\n",
    "print(cm)\n",
    "print(np.sum(cm))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm))/float(np.sum(cm))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how good is the DBSCAN grouping as an indicator of trace quality.\n",
    "dbscan_group = df['Group_id'].copy()\n",
    "primary_group_mask = (dbscan_group == 0)\n",
    "dbscan_group[primary_group_mask] = 'a'\n",
    "dbscan_group[~primary_group_mask] = 'b'\n",
    "cm_dbscan = confusion_matrix(df.loc[known_quality_mask, 'Quality'], dbscan_group[known_quality_mask], labels=['b', 'a'])\n",
    "print(cm_dbscan)\n",
    "print(np.sum(cm_dbscan))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm_dbscan))/float(np.sum(cm_dbscan))))\n",
    "# Result here indicates DBSCAN grouping is not a strong predictor of subjective trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how good SNR alone is as an indicator of trace quality.\n",
    "snr_series = df['SNR'].copy()\n",
    "high_snr_mask = (snr_series >= 2.0)\n",
    "snr_series[high_snr_mask] = 'a'\n",
    "snr_series[~high_snr_mask] = 'b'\n",
    "cm_snr = confusion_matrix(df.loc[known_quality_mask, 'Quality'], snr_series[known_quality_mask], labels=['b', 'a'])\n",
    "print(cm_snr)\n",
    "print(np.sum(cm_snr))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm_snr))/float(np.sum(cm_snr))))\n",
    "# Result here indicates SNR alone is quite a good indicator of quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how good coherence alone is as an indicator of trace quality.\n",
    "coh_series = df['Coherence'].copy()\n",
    "high_coh_mask = (coh_series >= 0.25)\n",
    "coh_series[high_coh_mask] = 'a'\n",
    "coh_series[~high_coh_mask] = 'b'\n",
    "cm_coh = confusion_matrix(df.loc[known_quality_mask, 'Quality'], coh_series[known_quality_mask], labels=['b', 'a'])\n",
    "print(cm_coh)\n",
    "print(np.sum(cm_coh))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm_coh))/float(np.sum(cm_coh))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist classifier model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = training_station + \"_classifier_{}.pkl\".format(rf_type)\n",
    "with open(model_file, 'wb') as f:\n",
    "    pkl.dump(clf_simple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
