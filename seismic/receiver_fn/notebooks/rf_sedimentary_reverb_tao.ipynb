{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# Kai Tao, Tianze Liu, Jieyuan Ning, Fenglin Niu, \"Estimating sedimentary and crustal structure\n",
    "# using wavefield continuation: theory, techniques and applications\", Geophysical Journal International,\n",
    "# Volume 197, Issue 1, April, 2014, Pages 443-457, https://doi.org/10.1093/gji/ggt515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('α β p ρ μ ω', positive=True, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('z z0 t t0 t1', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = ρ*β**2\n",
    "μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_α = sympy.sqrt(1/α**2 - p**2)\n",
    "q_α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_β = sympy.sqrt(1/β**2 - p**2)\n",
    "q_β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 1/β**2 - 2*p**2\n",
    "η"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = sympy.Matrix([\n",
    "    [         α*p,         α*p,       β*q_β,       β*q_β],\n",
    "    [       α*q_α,      -α*q_α,        -β*p,         β*p],\n",
    "    [-2*α*μ*p*q_α, 2*α*μ*p*q_α,      -β*μ*η,       β*μ*η],\n",
    "    [      -α*μ*η,      -α*μ*η, 2*β*μ*p*q_β, 2*β*μ*p*q_β]\n",
    "])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minv = (1/ρ)*sympy.Matrix([\n",
    "    [        μ*p/α,  η*μ/(2*α*q_α), -p/(2*α*q_α),    -1/(2*α)],\n",
    "    [        μ*p/α, -η*μ/(2*α*q_α),  p/(2*α*q_α),    -1/(2*α)],\n",
    "    [η*μ/(2*β*q_β),         -μ*p/β,     -1/(2*β), p/(2*β*q_β)],\n",
    "    [η*μ/(2*β*q_β),          μ*p/β,      1/(2*β), p/(2*β*q_β)]\n",
    "])\n",
    "Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deig = sympy.diag(-q_α, q_α, -q_β, q_β)\n",
    "deig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lame constant\n",
    "λ = ρ*(α**2 - 2*β**2)\n",
    "λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 4*μ*(λ + μ)/(λ + 2*μ)\n",
    "γ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sympy.Matrix([\n",
    "    [0, p, 1/μ, 0],\n",
    "    [p*λ/(λ + 2*μ), 0, 0, 1/(λ + 2*μ)],\n",
    "    [ρ - (p**2)*γ, 0, 0, p*λ/(λ + 2*μ)],\n",
    "    [0, ρ, p, 0]\n",
    "])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.simplify(A - M*deig*Minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdiag = sympy.diag(sympy.exp(sympy.I*ω*q_α*(z - z0)),\n",
    "                   sympy.exp(-sympy.I*ω*q_α*(z - z0)),\n",
    "                   sympy.exp(sympy.I*ω*q_β*(z - z0)),\n",
    "                   sympy.exp(-sympy.I*ω*q_β*(z - z0)))\n",
    "Pdiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = M*Pdiag*Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study case of half-space with no layers (mantle only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('v_r0 v_z0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = P.subs([(z0, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Minv*P0*sympy.Matrix([v_r0, v_z0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_up = sympy.simplify(w[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "St_up = sympy.InverseFourierTransform(S_up, ω, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "St_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jz_Sup = -ρ*(β**2)*q_β*sympy.Abs(St_up)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jz_Sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = sympy.Integral(Jz_Sup, (t, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units of density don't matter since it turns out to be just a scaling factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some data and start computing cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import numpy.fft as fft\n",
    "\n",
    "import h5py\n",
    "import obspy\n",
    "import obspyh5\n",
    "\n",
    "from seismic.receiver_fn.stream_quality_filter import curate_stream3c\n",
    "from seismic.receiver_fn.rf_util import compute_vertical_snr\n",
    "from seismic.receiver_fn.rf_util import KM_PER_DEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test first on non-sedimentary station since the theory is supposed to still work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'OA'\n",
    "target_station = 'BT23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling rate\n",
    "f_s = 10.0\n",
    "# Time window of original data to use for processing. All traces must have at least this extent\n",
    "# about the onset time.\n",
    "TIME_WINDOW = (-20, 60)\n",
    "# Narrower time window used for integration of energy flux\n",
    "FLUX_WINDOW = (-10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = (r\"/g/data/ha3/am7399/shared/OA_RF_analysis/\" +\n",
    "            r\"OA_event_waveforms_for_rf_20170911T000036-20181128T230620_rev8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for tr in obspyh5.iterh5(src_file, group='/waveforms/{}.{}.0M'.format(network, target_station), mode='r'):\n",
    "    traces.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group triplets of traces for same event id\n",
    "data_all = defaultdict(obspy.Stream)\n",
    "for tr in traces:\n",
    "    data_all[tr.stats.event_id].append(tr.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order traces into ZNE order.\n",
    "# Trim traces to analysis time window.\n",
    "for evid, stream in data_all.items():\n",
    "    stream.trim(stream[0].stats.onset + TIME_WINDOW[0],\n",
    "                stream[0].stats.onset + TIME_WINDOW[1])\n",
    "    stream.sort(keys=['channel'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[list(data_all.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply curation to streams prior to rotation\n",
    "logger = logging.getLogger(__name__)\n",
    "discard_ids = []\n",
    "for evid, stream in data_all.items():\n",
    "    if not curate_stream3c(evid, stream, logger):\n",
    "        discard_ids.append(evid)\n",
    "\n",
    "for evid in discard_ids:\n",
    "    data_all.pop(evid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate to ZRT coordinates\n",
    "for evid, stream in data_all.items():\n",
    "    stream.rotate('NE->RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data_all[list(data_all.keys())[0]]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend and taper the traces\n",
    "for evid, stream in data_all.items():\n",
    "    stream.detrend('linear')\n",
    "    stream.taper(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data[0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to lower sampling rate\n",
    "for evid, stream in data_all.items():\n",
    "    stream.filter('bandpass', freqmin=0.02, freqmax=f_s/2.0, corners=2, zerophase=True).interpolate(f_s, method='lanczos', a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNR of Z component to use as a quality metric\n",
    "for evid, stream in data_all.items():\n",
    "    compute_vertical_snr(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data[0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.array([s[0].stats.snr_prior for _, s in data_all.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(snrs, bins=np.linspace(0, 10, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_ids = []\n",
    "for evid, stream in data_all.items():\n",
    "    if stream[0].stats.snr_prior < 2.0:\n",
    "        discard_ids.append(evid)\n",
    "        \n",
    "for evid in discard_ids:\n",
    "    data_all.pop(evid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data_all[list(data_all.keys())[0]]\n",
    "# sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all traces have the same number of samples.\n",
    "assert(np.all(np.array([tr.stats.npts for st in data_all.values() for tr in st]) == \n",
    "              data_all[list(data_all.keys())[0]][0].stats.npts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update this to use dask instead of numpy, so that results will be computed lazily\n",
    "# using metaprogramming and graph pruning pre-optimization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract seismic waveforms\n",
    "\n",
    "Extract time series for Vr and Vz from data_all and shape into 3D array. First dimension is the event so that the 2nd and 3rd dimensions are the wave component (r and z) and time axis respectively. This choice of data layout is made for compatibility with numpy broadcast rules, which applies matrix operations to the last two dimensions and treats the first dimension as an ensemble stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here that we negate the z-component, since this method treats as +z as downwards (increasing depth).\n",
    "# V0 represents P-SV signal at the surface, i.e. that recorded by surface seismometer.\n",
    "v0 = np.array([[st[1].data.tolist(), (-st[0].data).tolist()] for st in data_all.values()])\n",
    "v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ray params for the events\n",
    "p = np.array([st[0].stats.slowness/KM_PER_DEG for st in data_all.values()])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_matrices(Vp, Vs, rho, p):\n",
    "    \"\"\"Compute M, M_inv and Q for a single layer for a scalar or array of ray parameters p.\n",
    "    \n",
    "    :param Vp: P-wave body wave velocity (scalar, labeled α in Tao's paper)\n",
    "    :type Vp: \n",
    "    :param Vs: S-wave body wave velocity (scalar, labeled β in Tao's paper)\n",
    "    :type Vs: \n",
    "    :param rho: Bulk material density, ρ (scalar)\n",
    "    :type rho: \n",
    "    :param p: Scalar or array of ray parameters (one per event)\n",
    "    :type p: \n",
    "    \"\"\"\n",
    "    qa = np.sqrt(1/Vp**2 - p*p)\n",
    "    qb = np.sqrt(1/Vs**2 - p*p)\n",
    "    eta = 1/Vs**2 - 2*p*p\n",
    "    mu = rho*Vs*Vs\n",
    "    trp = 2*mu*p*qa\n",
    "    trs = 2*mu*p*qb\n",
    "    mu_eta = mu*eta\n",
    "    # First compute without velocity factors for reduced operation count.\n",
    "    M = np.array([\n",
    "        [p, p, qb, qb],\n",
    "        [qa, -qa, -p, p],\n",
    "        [-trp, trp, -mu_eta, mu_eta],\n",
    "        [-mu_eta, -mu_eta, trs, trs]\n",
    "    ])\n",
    "    # Then times by velocity factors\n",
    "    Vfactors = np.diag([Vp, Vp, Vs, Vs])\n",
    "    M = np.matmul(np.moveaxis(M, -1, 0), Vfactors)\n",
    "    \n",
    "    Q = np.diag([qa, -qa, qb, -qb])\n",
    "\n",
    "    # First compute without velocity factors for reduced operation count.\n",
    "    mu_p = mu*p\n",
    "    Minv = (1.0/rho)*np.array([\n",
    "        [mu_p, mu_eta/2/qa, -p/2/qa, -0.5*np.ones(p.shape)],\n",
    "        [mu_p, -mu_eta/2/qa, p/2/qa, -0.5*np.ones(p.shape)],\n",
    "        [mu_eta/2/qb, -mu_p, -0.5*np.ones(p.shape), p/2/qb],\n",
    "        [mu_eta/2/qb, mu_p, 0.5*np.ones(p.shape), p/2/qb]\n",
    "    ])\n",
    "    # Then times by velocity factors\n",
    "    Vfactors_inv = np.diag([1/Vp, 1/Vp, 1/Vs, 1/Vs])\n",
    "    Minv = np.matmul(Vfactors_inv, np.moveaxis(Minv, -1, 0))\n",
    "    \n",
    "    return (M, Minv, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerProps():\n",
    "    # Helper class to contain layer bulk material properties\n",
    "    def __init__(self, vp, vs, rho, z_base):\n",
    "        self.Vp = vp\n",
    "        self.Vs = vs\n",
    "        self.rho = rho\n",
    "        self.H = z_base # H value relative to surface for this layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_layers(fv0, w, layer_props, p):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fz = fv0\n",
    "    for layer in layer_props:\n",
    "        M, Minv, Q = mode_matrices(layer.Vp, layer.Vs, layer.rho, p)\n",
    "        fz = np.matmul(Minv[:,:,0:2], fz)\n",
    "        phase_args = np.outer(Q - Q[1], w)\n",
    "#         phase_args = np.outer(Q, w)\n",
    "        phase_factors = np.exp(-1j*layer.H*phase_args) # shouldn't this H[i] rather be H[i] - H[i-1]?\n",
    "        fz = fz*phase_factors\n",
    "        fz = np.matmul(M, fz)\n",
    "    # end for\n",
    "    return fz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_su_energy(v0, f_s, p, mantle_props, layer_props,\n",
    "                      time_window=TIME_WINDOW, flux_window=FLUX_WINDOW):\n",
    "    \"\"\"Compute upgoing S-wave energy for a given set of seismic time series v0.\n",
    "    \"\"\"\n",
    "    dt = 1.0/f_s\n",
    "    npts = v0.shape[2]\n",
    "    nevts = v0.shape[0]\n",
    "    t = np.linspace(*time_window, npts)\n",
    "\n",
    "    # Reshape to facilitate max_vz normalization using numpy broadcast rules.\n",
    "    v0 = np.moveaxis(v0, 0, -1)\n",
    "\n",
    "    # Normalize each event signal by the maximum z-component amplitude.\n",
    "    # We perform this succinctly using numpy multidimensional broadcasting rules.\n",
    "    max_vz = v0[1,:,:].max(axis=0)\n",
    "    v0 = v0/max_vz\n",
    "\n",
    "    # Reshape back to original shape.\n",
    "    v0 = np.moveaxis(v0, -1, 0)\n",
    "\n",
    "    # Transform v0 to the spectral domain using real FFT\n",
    "    fv0 = np.fft.rfft(v0, axis=-1)\n",
    "\n",
    "    # Compute discrete frequencies\n",
    "    w = 2*np.pi*np.fft.rfftfreq(v0.shape[-1], dt)\n",
    "\n",
    "    # Extend w to full spectral domain.\n",
    "    w_full = np.hstack((w, -np.flipud(w[1:])))\n",
    "\n",
    "    # To extend fv0, we need to flip left-right and take complex conjugate.\n",
    "    fv0_full = np.dstack((fv0, np.fliplr(np.conj(fv0[:, :, 1:]))))\n",
    "\n",
    "    # Compute mode matrices for mantle\n",
    "    M_m, Minv_m, _ = mode_matrices(mantle_props.Vp, mantle_props.Vs, mantle_props.rho, p)\n",
    "\n",
    "    # Propagate from surface\n",
    "    fv1 = propagate_layers(fv0_full, w_full, layer_props, p)\n",
    "\n",
    "    num_pos_freq_terms = (fv1.shape[2] + 1)//2\n",
    "    v1 = np.fft.irfft(fv1[:, :, :num_pos_freq_terms], fv1.shape[2], axis=2)\n",
    "\n",
    "    vm = np.matmul(Minv_m, v1)\n",
    "\n",
    "    # Compute coefficients of energy integral for upgoing S-wave\n",
    "    qb_m = np.sqrt(1/mantle_props.Vs**2 - p*p)\n",
    "    Nsu = dt*mantle_props.rho*(mantle_props.Vs**2)*qb_m\n",
    "\n",
    "    # Compute mask for the energy integral time window\n",
    "    integral_mask = (t >= flux_window[0]) & (t <= flux_window[1])\n",
    "    vm_windowed = vm[:, :, integral_mask]\n",
    "\n",
    "    # Take the su component.\n",
    "    su_windowed = vm_windowed[:, 3, :]\n",
    "\n",
    "    # Integrate in time\n",
    "    Esu_per_event = Nsu*np.sum(np.abs(su_windowed)**2, axis=1)\n",
    "\n",
    "    # Compute mean over events\n",
    "    Esu = np.mean(Esu_per_event)\n",
    "\n",
    "    return Esu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bulk properties of mantle (lowermost half-space)\n",
    "mantle_props = LayerProps(8.0, 4.5, 3.3, np.Infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define single layer earth model (crust over mantle only, no sediment)\n",
    "# Vs here is postulated.\n",
    "# H here is postulated.\n",
    "earth_props = np.array([LayerProps(6.4, 3.7, 2.7, 35.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_su_energy(v0, f_s, p, mantle_props, earth_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of grid search over H,Vs space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H, Vs = np.meshgrid(np.linspace(30, 50, 201), np.linspace(3.0, 4.5, 151))\n",
    "H, Vs = np.meshgrid(np.linspace(25, 55, 151), np.linspace(3.2, 4.2, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Esu = np.zeros(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "IntProgress(10, max=100)\n",
    "FloatProgress(10, max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (H_arr, Vs_arr) in tqdm(enumerate(zip(H, Vs)), desc='Outer loop'):\n",
    "    for j, (_H, _Vs) in tqdm(enumerate(zip(H_arr, Vs_arr)), desc='Inner loop'):\n",
    "        earth_props = np.array([LayerProps(6.4, _Vs, 2.7, _H)])\n",
    "        Esu[i, j] = compute_su_energy(v0, f_s, p, mantle_props, earth_props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(Esu.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmap = 'plasma'\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "plt.contourf(Vs, H, Esu, levels=50, cmap=colmap)\n",
    "cb = plt.colorbar()\n",
    "plt.contour(Vs, H, Esu, levels=10, colors='k', linewidths=1, antialiased=True)\n",
    "plt.xlabel('$V_s$ (km/s)', fontsize=14)\n",
    "plt.ylabel('$H$ Moho depth (km)', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(right=True, labelright=True, which='both')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.minorticks_on()\n",
    "plt.xlim(np.min(Vs), np.max(Vs))\n",
    "plt.ylim(np.min(H), np.max(H))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
