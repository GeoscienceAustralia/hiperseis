{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# Kai Tao, Tianze Liu, Jieyuan Ning, Fenglin Niu, \"Estimating sedimentary and crustal structure\n",
    "# using wavefield continuation: theory, techniques and applications\", Geophysical Journal International,\n",
    "# Volume 197, Issue 1, April, 2014, Pages 443-457, https://doi.org/10.1093/gji/ggt515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.init_printing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('α β p ρ μ ω', positive=True, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('z z0 t t0 t1', real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = ρ*β**2\n",
    "μ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_α = sympy.sqrt(1/α**2 - p**2)\n",
    "q_α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_β = sympy.sqrt(1/β**2 - p**2)\n",
    "q_β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 1/β**2 - 2*p**2\n",
    "η"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = sympy.Matrix([\n",
    "    [         α*p,         α*p,       β*q_β,       β*q_β],\n",
    "    [       α*q_α,      -α*q_α,        -β*p,         β*p],\n",
    "    [-2*α*μ*p*q_α, 2*α*μ*p*q_α,      -β*μ*η,       β*μ*η],\n",
    "    [      -α*μ*η,      -α*μ*η, 2*β*μ*p*q_β, 2*β*μ*p*q_β]\n",
    "])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minv = (1/ρ)*sympy.Matrix([\n",
    "    [        μ*p/α,  η*μ/(2*α*q_α), -p/(2*α*q_α),    -1/(2*α)],\n",
    "    [        μ*p/α, -η*μ/(2*α*q_α),  p/(2*α*q_α),    -1/(2*α)],\n",
    "    [η*μ/(2*β*q_β),         -μ*p/β,     -1/(2*β), p/(2*β*q_β)],\n",
    "    [η*μ/(2*β*q_β),          μ*p/β,      1/(2*β), p/(2*β*q_β)]\n",
    "])\n",
    "Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deig = sympy.diag(-q_α, q_α, -q_β, q_β)\n",
    "deig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lame constant\n",
    "λ = ρ*(α**2 - 2*β**2)\n",
    "λ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 4*μ*(λ + μ)/(λ + 2*μ)\n",
    "γ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sympy.Matrix([\n",
    "    [0, p, 1/μ, 0],\n",
    "    [p*λ/(λ + 2*μ), 0, 0, 1/(λ + 2*μ)],\n",
    "    [ρ - (p**2)*γ, 0, 0, p*λ/(λ + 2*μ)],\n",
    "    [0, ρ, p, 0]\n",
    "])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.simplify(A - M*deig*Minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdiag = sympy.diag(sympy.exp(sympy.I*ω*q_α*(z - z0)),\n",
    "                   sympy.exp(-sympy.I*ω*q_α*(z - z0)),\n",
    "                   sympy.exp(sympy.I*ω*q_β*(z - z0)),\n",
    "                   sympy.exp(-sympy.I*ω*q_β*(z - z0)))\n",
    "Pdiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = M*Pdiag*Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study case of half-space with no layers (mantle only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sympy.var('v_r0 v_z0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P0 = P.subs([(z0, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Minv*P0*sympy.Matrix([v_r0, v_z0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_up = sympy.simplify(w[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "St_up = sympy.InverseFourierTransform(S_up, ω, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "St_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jz_Sup = -ρ*(β**2)*q_β*sympy.Abs(St_up)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jz_Sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = sympy.Integral(Jz_Sup, (t, t0, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units of density don't matter since it turns out to be just a scaling factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some data and start computing cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import numpy.fft as fft\n",
    "\n",
    "import h5py\n",
    "import obspy\n",
    "import obspyh5\n",
    "\n",
    "from seismic.receiver_fn.stream_quality_filter import curate_stream3c\n",
    "from seismic.receiver_fn.rf_util import compute_vertical_snr\n",
    "from seismic.receiver_fn.rf_util import KM_PER_DEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test first on non-sedimentary station since the theory is supposed to still work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'OA'\n",
    "target_station = 'BT23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling rate\n",
    "f_s = 10.0\n",
    "# Time window of original data to use for processing. All traces must have at least this extent\n",
    "# about the onset time.\n",
    "TIME_WINDOW = (-20, 60)\n",
    "# Narrower time window used for integration of energy flux\n",
    "FLUX_WINDOW = (-10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = r\"/g/data1a/ha3/am7399/shared/OA_RF_analysis/OA_event_waveforms_for_rf_20170911T000036-20181128T230620_rev8.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for tr in obspyh5.iterh5(src_file, group='/waveforms/{}.{}.0M'.format(network, target_station), mode='r'):\n",
    "    traces.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group triplets of traces for same event id\n",
    "data_all = defaultdict(obspy.Stream)\n",
    "for tr in traces:\n",
    "    data_all[tr.stats.event_id].append(tr.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order traces into ZNE order.\n",
    "# Trim traces to analysis time window.\n",
    "for evid, stream in data_all.items():\n",
    "    stream.trim(stream[0].stats.onset + TIME_WINDOW[0],\n",
    "                stream[0].stats.onset + TIME_WINDOW[1])\n",
    "    stream.sort(keys=['channel'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[list(data_all.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply curation to streams prior to rotation\n",
    "logger = logging.getLogger(__name__)\n",
    "discard_ids = []\n",
    "for evid, stream in data_all.items():\n",
    "    if not curate_stream3c(evid, stream, logger):\n",
    "        discard_ids.append(evid)\n",
    "\n",
    "for evid in discard_ids:\n",
    "    data_all.pop(evid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate to ZRT coordinates\n",
    "for evid, stream in data_all.items():\n",
    "    stream.rotate('NE->RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data_all[list(data_all.keys())[0]]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend and taper the traces\n",
    "for evid, stream in data_all.items():\n",
    "    stream.detrend('linear')\n",
    "    stream.taper(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data[0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to lower sampling rate\n",
    "for evid, stream in data_all.items():\n",
    "    stream.filter('bandpass', freqmin=0.02, freqmax=f_s/2.0, corners=2, zerophase=True).interpolate(f_s, method='lanczos', a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SNR of Z component to use as a quality metric\n",
    "for evid, stream in data_all.items():\n",
    "    compute_vertical_snr(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data[0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.array([s[0].stats.snr_prior for _, s in data_all.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(snrs, bins=np.linspace(0, 10, 21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_ids = []\n",
    "for evid, stream in data_all.items():\n",
    "    if stream[0].stats.snr_prior < 2.0:\n",
    "        discard_ids.append(evid)\n",
    "        \n",
    "for evid in discard_ids:\n",
    "    data_all.pop(evid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = data_all[list(data_all.keys())[0]]\n",
    "sample_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all(np.array([tr.stats.npts for st in data_all.values() for tr in st]) == \n",
    "              data_all[list(data_all.keys())[0]][0].stats.npts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update this to use dask instead of numpy, so that results will be computed lazily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1.0/f_s\n",
    "npts = data_all[list(data_all.keys())[0]][0].stats.npts\n",
    "nevts = len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(*TIME_WINDOW, npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time series for Vr and Vz from data_all and shape into 3D array. First row is Vr, second row is Vz.\n",
    "# The time series is in the second (column) direction.\n",
    "# The third (depth) dimension is the number of events. Each depth plane is Vr, Vz time series for one event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note here that we negate the z-component, since this method as +z as downwards (increasing depth).\n",
    "# V0 represents P-SV signal at the surface, i.e. that recorded by surface seismometer.\n",
    "v0 = np.array([[st[1].data.tolist(), (-st[0].data).tolist()] for st in data_all.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = np.moveaxis(v0, 0, -1)\n",
    "v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each event signal by the maximum z-component amplitude.\n",
    "# We perform this succinctly using numpy multidimensional broadcasting rules.\n",
    "max_vz = v0[1,:,:].max(axis=0)\n",
    "max_vz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = v0/max_vz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform v0 to the spectral domain using real FFT\n",
    "fv0 = np.fft.rfft(v0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute discrete frequencies\n",
    "w = 2*np.pi*np.fft.rfftfreq(v0.shape[1], dt)\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend w to full spectral domain.\n",
    "w_full = np.hstack((w, -np.flipud(w[1:])))\n",
    "w_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To extend fv0, we need to flip left-right and take complex conjugate.\n",
    "fv0_full = np.hstack((fv0, np.fliplr(np.conj(fv0[:, 1:, :]))))\n",
    "fv0_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv0_full = np.moveaxis(fv0_full, -1, 0)\n",
    "fv0_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ray params for the events\n",
    "p = np.array([st[0].stats.slowness/KM_PER_DEG for st in data_all.values()])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_matrices(Vp, Vs, rho, p):\n",
    "    \"\"\"Compute M, M_inv and Q for a single layer for a scalar or array of ray parameters p.\n",
    "    \n",
    "    Vp: alpha (scalar)\n",
    "    Vs: beta (scalar)\n",
    "    rho: rho (scalar)\n",
    "    p: scalar or array of ray parameters (one per event)\n",
    "    \"\"\"\n",
    "    qa = np.sqrt(1/Vp**2 - p*p)\n",
    "    qb = np.sqrt(1/Vs**2 - p*p)\n",
    "    eta = 1/Vs**2 - 2*p*p\n",
    "    mu = rho*Vs*Vs\n",
    "    trp = 2*mu*p*qa\n",
    "    trs = 2*mu*p*qb\n",
    "    mu_eta = mu*eta\n",
    "    # First compute without velocity factors for reduced operation count.\n",
    "    M = np.array([\n",
    "        [p, p, qb, qb],\n",
    "        [qa, -qa, -p, p],\n",
    "        [-trp, trp, -mu_eta, mu_eta],\n",
    "        [-mu_eta, -mu_eta, trs, trs]\n",
    "    ])\n",
    "    # Then times by velocity factors\n",
    "    Vfactors = np.diag([Vp, Vp, Vs, Vs])\n",
    "    M = np.matmul(np.moveaxis(M, -1, 0), Vfactors)\n",
    "    \n",
    "    Q = np.diag([qa, -qa, qb, -qb])\n",
    "\n",
    "    # First compute without velocity factors for reduced operation count.\n",
    "    mu_p = mu*p\n",
    "    Minv = (1.0/rho)*np.array([\n",
    "        [mu_p, mu_eta/2/qa, -p/2/qa, -0.5*np.ones(p.shape)],\n",
    "        [mu_p, -mu_eta/2/qa, p/2/qa, -0.5*np.ones(p.shape)],\n",
    "        [mu_eta/2/qb, -mu_p, -0.5*np.ones(p.shape), p/2/qb],\n",
    "        [mu_eta/2/qb, mu_p, 0.5*np.ones(p.shape), p/2/qb]\n",
    "    ])\n",
    "    # Then times by velocity factors\n",
    "    Vfactors_inv = np.diag([1/Vp, 1/Vp, 1/Vs, 1/Vs])\n",
    "    Minv = np.matmul(Vfactors_inv, np.moveaxis(Minv, -1, 0))\n",
    "    \n",
    "    return (M, Minv, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vp = 6.4\n",
    "Vs = 3.7\n",
    "rho = 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, Minv, Q = mode_matrices(Vp, Vs, rho, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv0_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_layers(fv0, w, H, Vp, Vs, rho, p):\n",
    "    nlayers = len(Vp)\n",
    "    assert len(Vs) == len(rho) == len(H) == nlayers\n",
    "    fz = fv0\n",
    "    for i in range(nlayers):\n",
    "        M, Minv, Q = mode_matrices(Vp[i], Vs[i], rho[i], p)\n",
    "        fz = np.matmul(Minv[:,:,0:2], fz)\n",
    "        phase_args = np.outer(Q - Q[1], w)\n",
    "        phase_factors = np.exp(-1j*H[i]*phase_args) # shouldn't this H[i] rather be H[i] - H[i-1]?\n",
    "        fz = fz*phase_factors\n",
    "        fz = np.matmul(M, fz)\n",
    "    # end for\n",
    "    return fz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = np.matmul(Minv[:,:,0:2], fv0_full)\n",
    "fz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_args = np.outer(Q - Q[1], w_full)\n",
    "phase_args.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_factors = np.exp(-1j*H*phase_args)\n",
    "phase_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = fz*phase_factors\n",
    "fz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = np.matmul(M, fz)\n",
    "fz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
