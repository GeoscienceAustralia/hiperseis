{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import rf\n",
    "import rf.imaging\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "import obspy\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = \"/g/data/ha3/am7399/shared/OA_event_waveforms_for_rf_20170911T000036-20181128T230620_ZRT_td_rev3.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oa_all = rf.read_rf(src_file, format='h5', group='/waveforms/OA.BT23.0M')\n",
    "oa_all = rf.read_rf(src_file, format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_to_dict(rf_data):\n",
    "    db = defaultdict(lambda: defaultdict(list))\n",
    "    for s in rf_data:\n",
    "        _, sta, _, cha = s.id.split('.')\n",
    "        db[sta][cha].append(s)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_station_rf_overlays(db_station):\n",
    "    plt.figure(figsize=(16,24))\n",
    "    colors = [\"#8080a040\", \"#80a08040\", \"#a0808040\"]\n",
    "    min_x = 1e+20\n",
    "    max_x = -1e20\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        col = colors[i]\n",
    "        plt.subplot(3, 1, i + 1)\n",
    "        sta = streams[0].stats.station\n",
    "        plt.title('.'.join([sta, ch]), fontsize=14)\n",
    "        for j, s in enumerate(streams):\n",
    "            lead_time = s.stats.onset - s.stats.starttime\n",
    "            times = s.times()\n",
    "            plt.plot(times - lead_time, s.data, '--', color=col, linewidth=2)\n",
    "            if j == 0:\n",
    "                data_mean = s.data\n",
    "            else:\n",
    "                data_mean += s.data\n",
    "        data_mean /= float(j)\n",
    "        plt.plot(s.times() - lead_time, data_mean, color=\"#202020\", linewidth=2)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude (normalized)')\n",
    "        plt.grid(linestyle=':', color=\"#80808020\")\n",
    "        x_lims = plt.xlim()\n",
    "        min_x = min(min_x, x_lims[0])\n",
    "        max_x = max(max_x, x_lims[1])\n",
    "    for i in range(3):\n",
    "        subfig = plt.subplot(3, 1, i + 1)\n",
    "        subfig.set_xlim((min_x, max_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_nth_root(arr, order):\n",
    "    if order == 1:\n",
    "        return arr\n",
    "    else:\n",
    "        return np.sign(arr)*np.power(np.abs(arr), 1.0/order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_nth_power(arr, order):\n",
    "    if order == 1:\n",
    "        return arr\n",
    "    else:\n",
    "        return np.sign(arr)*np.power(np.abs(arr), order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hk_stack(db_station, cha, h_range=np.linspace(10.0, 70.0, 301), k_range = np.linspace(1.3, 2.1, 201),\n",
    "                     V_p = 6.4, root_order=1, include_t3=True):\n",
    "\n",
    "    # Pre-compute grid quantities\n",
    "    k_grid, h_grid = np.meshgrid(k_range, h_range)\n",
    "    hk_stack = np.zeros_like(k_grid)\n",
    "    H_on_V_p = h_grid/V_p\n",
    "    k2 = k_grid*k_grid\n",
    "\n",
    "    stream_stack = []\n",
    "    cha_data = db_station[cha]\n",
    "    # Loop over streams, compute times, and stack interpolated values at those times\n",
    "    for s in cha_data:\n",
    "        incidence = s.stats.inclination\n",
    "        incidence_rad = incidence*np.pi/180.0\n",
    "        cos_i, sin_i = np.cos(incidence_rad), np.sin(incidence_rad)\n",
    "        sin2_i = sin_i*sin_i\n",
    "        term1 = H_on_V_p*k_grid*np.abs(cos_i)\n",
    "        term2 = H_on_V_p*np.sqrt(1 - k2*sin2_i)\n",
    "        # Time for Ps\n",
    "        t1 = term1 - term2\n",
    "        # Time for PpPs\n",
    "        t2 = term1 + term2\n",
    "        if include_t3:\n",
    "            # Time for PpSs + PsPs\n",
    "            t3 = 2*term1\n",
    "\n",
    "        # Subtract lead time so that primary P-wave arrival is at time zero.\n",
    "        lead_time = s.stats.onset - s.stats.starttime\n",
    "        times = s.times() - lead_time\n",
    "        # Create interpolator from stream signal for accurate time sampling.\n",
    "        interpolator = interp1d(times, s.data, kind='linear', copy=False, bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        phase_sum = []\n",
    "        phase_sum.append(signed_nth_root(interpolator(t1), root_order))\n",
    "        phase_sum.append(signed_nth_root(interpolator(t2), root_order))\n",
    "        if include_t3:\n",
    "            # Negative sign on the third term is intentional, see Chen et al. (2010) and Zhu & Kanamori (2000).\n",
    "            # It needs to be negative because the PpSs + PsPs peak has negative phase,\n",
    "            # see http://eqseis.geosc.psu.edu/~cammon/HTML/RftnDocs/rftn01.html\n",
    "            # Apply nth root technique to reduce uncorrelated noise (Chen et al. (2010))\n",
    "            phase_sum.append(-signed_nth_root(interpolator(t3), root_order))\n",
    "\n",
    "        stream_stack.append(phase_sum)\n",
    "\n",
    "    # Perform the stacking (sum) across streams. hk_stack retains separate t1, t2, and t3 components here.\n",
    "    hk_stack = np.nanmean(np.array(stream_stack), axis=0)\n",
    "\n",
    "    # This inversion of the nth root is different to Sippl and Chen, but consistent with Muirhead\n",
    "    # who proposed the nth root technique. It improves the contrast of the resulting plot.\n",
    "    if root_order != 1:\n",
    "        hk_stack = signed_nth_power(hk_stack, root_order)\n",
    "\n",
    "    return k_grid, h_grid, hk_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_stack(hk_components, weighting=(0.5, 0.5, 0.0)):\n",
    "    assert hk_components.shape[0] == len(weighting), hk_components.shape\n",
    "    hk_phase_stacked = np.dot(np.moveaxis(hk_components, 0, -1), np.array(weighting))\n",
    "    return hk_phase_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hk_stack(k_grid, h_grid, hk_stack, title=None, save_file=None, show=True, num=None, clip_negative=True):\n",
    "    # Call computed_weighted_stack() first to combine weighted components before calling this function.\n",
    "    # Use a perceptually linear color map.\n",
    "    colmap = 'plasma'\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    if clip_negative:\n",
    "        hk_stack[hk_stack < 0] = 0\n",
    "    plt.contourf(k_grid, h_grid, hk_stack, levels=50, cmap=colmap)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.set_ylabel('Stack sum')\n",
    "    plt.contour(k_grid, h_grid, hk_stack, levels=10, colors='k', linewidths=1)\n",
    "    plt.xlabel(r'$\\kappa = \\frac{V_p}{V_s}$ (ratio)', fontsize=14)\n",
    "    plt.ylabel('H = Moho depth (km)', fontsize=14)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    if num is not None:\n",
    "        xl = plt.xlim()\n",
    "        yl = plt.ylim()\n",
    "        txt_x = xl[0] + 0.85*(xl[1] - xl[0])\n",
    "        txt_y = yl[0] + 0.95*(yl[1] - yl[0])\n",
    "        plt.text(txt_x, txt_y, \"N = {}\".format(num), color=\"#ffffff\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    if save_file is not None:\n",
    "        tries = 10\n",
    "        while tries > 0:\n",
    "            try:\n",
    "                tries -= 1\n",
    "                plt.savefig(save_file, dpi=300)\n",
    "                break\n",
    "            except PermissionError:\n",
    "                time.sleep(1)\n",
    "                if tries == 0:\n",
    "                    print(\"WARNING: Failed to save file {} due to permissions!\".format(save_file))\n",
    "                    break\n",
    "            # end try\n",
    "        # end while\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_station_streams(db_station, freq_band=(None, None)):\n",
    "    \"\"\"Perform frequency filtering on streams. Returns a replica of db_station with streams containing filtered results.\n",
    "    \"\"\"\n",
    "    db_station_filt = defaultdict(list)\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        if ch == 'size' or i >= 3:\n",
    "            continue\n",
    "        for j, s in enumerate(streams):\n",
    "            stream_filt = s.copy()\n",
    "            if freq_band[0] is None and freq_band[1] is not None:\n",
    "                stream_filt.filter('lowpass', zerophase=True, corners=2, freq=freq_band[1])\n",
    "            elif freq_band[0] is not None and freq_band[1] is None:\n",
    "                stream_filt.filter('highpass', zerophase=True, corners=2, freq=freq_band[0])\n",
    "            elif freq_band[0] is not None and freq_band[1] is not None:\n",
    "                stream_filt.filter('bandpass', zerophase=True, corners=2, freqmin=freq_band[0],\n",
    "                                   freqmax=freq_band[1])\n",
    "            # end if\n",
    "            db_station_filt[ch].append(stream_filt)\n",
    "        # end for\n",
    "    # end for\n",
    "\n",
    "    return db_station_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_station_to_mean_signal(db_station, min_correlation=1.0):\n",
    "    \"\"\"Filter out streams which are not 'close enough' to the mean signal,\n",
    "       based on simple correlation score.\n",
    "    \"\"\"\n",
    "    # Compute mean signals of channels in station\n",
    "    mean_rfs = []\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        if ch == 'size' or i >= 3:\n",
    "            continue\n",
    "        for j, s in enumerate(streams):\n",
    "            if j == 0:\n",
    "                data_mean = s.data\n",
    "            else:\n",
    "                data_mean += s.data\n",
    "            # end if\n",
    "        # end for\n",
    "        data_mean /= float(j)\n",
    "        mean_rfs.append(data_mean)\n",
    "    # end for\n",
    "\n",
    "    # Filter out signals that do not meet minimum coherence with mean signal for each channel\n",
    "    db_station_filt = defaultdict(list)\n",
    "\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        for j, s in enumerate(streams):\n",
    "            corr = np.dot(s.data, mean_rfs[i])/np.dot(mean_rfs[i], mean_rfs[i])\n",
    "            if corr >= min_correlation:\n",
    "                db_station_filt[ch].append(s)\n",
    "        # end for\n",
    "    # end for\n",
    "                \n",
    "    return db_station_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select test station and plot overlaid stream data per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = rf_to_dict(oa_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# sta_codes = list(db.keys())\n",
    "# sta_lat = [db[sta]['HHR'][0].stats.station_latitude for sta in sta_codes]\n",
    "# sta_lon = [db[sta]['HHR'][0].stats.station_longitude for sta in sta_codes]\n",
    "# df_OA_sta = pd.DataFrame.from_dict({'Station': sta_codes, 'Latitude': sta_lat, 'Longitude': sta_lon})\n",
    "# df_OA_sta.to_csv('OA_stations.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for north-south lines\n",
    "# for sta in ['BV21', 'BV28', 'BX20', 'BX28', 'BY20', 'BY28', 'CB20', 'CB28', 'CD21', 'CD28']:\n",
    "#     lat = db[sta]['HHR'][0].stats.station_latitude\n",
    "#     lon = db[sta]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}: ({} {})\".format(sta, lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for west-east lines\n",
    "# for sta in ['BU22', 'CI22', 'BS26', 'CE26', 'BS28', 'CF28']:\n",
    "#     lat = db[sta]['HHR'][0].stats.station_latitude\n",
    "#     lon = db[sta]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}: ({} {})\".format(sta, lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for Andrew Clark\n",
    "# for i, sta_pair in enumerate([('BV21', 'CC28'), ('BX20', 'BX28'), ('BY20', 'BY28')]):\n",
    "#     if i == 0:\n",
    "#         # NE-->SW line\n",
    "#         lat0 = db[sta_pair[0]]['HHR'][0].stats.station_latitude + 0.1\n",
    "#         lon0 = db[sta_pair[0]]['HHR'][0].stats.station_longitude - 0.1\n",
    "#         lat1 = db[sta_pair[1]]['HHR'][0].stats.station_latitude - 0.1\n",
    "#         lon1 = db[sta_pair[1]]['HHR'][0].stats.station_longitude + 0.1\n",
    "#     else:\n",
    "#         # N-->S line\n",
    "#         lat0 = db[sta_pair[0]]['HHR'][0].stats.station_latitude + 0.1\n",
    "#         lon0 = db[sta_pair[0]]['HHR'][0].stats.station_longitude\n",
    "#         lat1 = db[sta_pair[1]]['HHR'][0].stats.station_latitude - 0.1\n",
    "#         lon1 = db[sta_pair[1]]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}-{}: --start-latlon {} {} --end-latlon {} {}\".format(sta_pair[0], sta_pair[1], lat0, lon0, lat1, lon1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test = db['BT23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_test['HHR'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_copy = oa_test['HHR'][0].copy()\n",
    "# tr_copy.filter('lowpass', zerophase=True, corners=2, freq=5.0)\n",
    "# tr_copy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test['HHR'][0].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_rf_overlays(oa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test_filt = filter_station_streams(oa_test, freq_band=(0.25, None))\n",
    "oa_test_filt = filter_station_to_mean_signal(oa_test_filt, min_correlation=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_station_rf_overlays(oa_test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test phase weighting\n",
    "s0 = oa_test_filt['HHR'][0]\n",
    "time_offset = s0.stats.onset - s0.stats.starttime\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, s0.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_h = signal.hilbert(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.imag(s0_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_angle = np.angle(s0_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, np.unwrap(s0_angle))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_iphase = np.exp(1j*s0_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = []\n",
    "tphase = []\n",
    "for s in oa_test_filt['HHR']:\n",
    "    analytic = signal.hilbert(s.data)\n",
    "    angle = np.angle(analytic)\n",
    "    angles.append(np.unwrap(angle))\n",
    "    iPhase = np.exp(1j*angle)\n",
    "    tphase.append(iPhase)\n",
    "tphase = np.array(tphase)\n",
    "tphase_mean = np.abs(np.mean(tphase,axis=0))\n",
    "tphase_norm = tphase_mean/np.max(tphase_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, np.array(angles).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, tphase_norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate effect of phase weighting to suppress areas where phases tend to be random.\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, s0.data, linewidth=2)\n",
    "plt.plot(s0.times() - time_offset, s0.data*tphase_norm, '--', linewidth=2)\n",
    "plt.legend(['Original', 'Phase weighted'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run over all channels to verify on HHR is the correct channel to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacks for all channels\n",
    "weighting = (0.4, 0.4, 0.2)\n",
    "# for cha in ['HHR', 'HHT', 'HHZ']:\n",
    "for cha in ['HHR']:\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(oa_test, cha, root_order=2)\n",
    "\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "    \n",
    "    sta = oa_test[cha][0].stats.station\n",
    "\n",
    "    num = len(oa_test[cha])\n",
    "    save_file = None\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack[0], title=sta + '.{} Ps'.format(cha), num=num)\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack[1], title=sta + '.{} PpPs'.format(cha), num=num)\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack[2], title=sta + '.{} PpSs + PsPs'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha), num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacks for all channels in filtered data\n",
    "weighting = (0.4, 0.4, 0.2)\n",
    "for cha in ['HHR']:\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(oa_test_filt, cha, root_order=2)\n",
    "\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "\n",
    "    sta = oa_test_filt[cha][0].stats.station\n",
    "\n",
    "    num = len(oa_test_filt[cha])\n",
    "    save_file = None\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha) + \" (filtered)\", num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over all OA stations and plot HK-stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha = 'HHR'\n",
    "pbar = tqdm(total=len(db))\n",
    "show = False\n",
    "weighting = (0.5, 0.4, 0.1)\n",
    "for sta, db_sta in db.items():\n",
    "    pbar.set_description(sta)\n",
    "    pbar.update()\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(db_sta, cha, root_order=2)\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "    sta = db_sta[cha][0].stats.station\n",
    "    save_file = sta + \"_{}_hk_stack.png\".format(cha)\n",
    "    num = len(db_sta[cha])\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha), save_file=save_file, show=show, num=num)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of group ID distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for sta, db_sta in db.items():\n",
    "    ch_data = db_sta['HHR']\n",
    "    for s in ch_data:\n",
    "        groups.append(s.stats.rf_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(groups)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of inclinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incs = []\n",
    "for sta, db_sta in db.items():\n",
    "    ch_data = db_sta['HHR']\n",
    "    for s in ch_data:\n",
    "        incs.append(s.stats.inclination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(incs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
