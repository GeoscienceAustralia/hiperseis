{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ conda env list\n",
    "# # conda environments:\n",
    "# #\n",
    "# base                  *  /g/data1a/ha3/fxz547/miniconda3\n",
    "# py37                     /g/data1a/ha3/fxz547/miniconda3/envs/py37\n",
    "\n",
    "\n",
    "# (base) fxz547@vdi-n11 /g/data1a/ha3/fxz547/Githubz/passive-seismic/seismic/ml_classifier (fei/py3aws)\n",
    "# $ conda activate py37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle,seed\n",
    "\n",
    "def build_input_data(data_folder):\n",
    "    \"\"\"build a list of IDs and dictionary of labels\n",
    "    \"\"\"\n",
    "    files=os.listdir(data_folder)\n",
    "    IDs=[]\n",
    "    for fname in files:\n",
    "        if fname.endswith('.npy'):\n",
    "            IDs.append(fname.rstrip('.npy'))\n",
    "\n",
    "    labels={}\n",
    "    Sctr=0\n",
    "    Nctr=0\n",
    "    for ID in IDs:\n",
    "        if ID.endswith('_S'):\n",
    "            labels[ID]=0\n",
    "            Sctr+=1\n",
    "        else:\n",
    "            labels[ID]=1\n",
    "            Nctr+=1\n",
    "\n",
    "    seed(0)\n",
    "    shuffle(IDs)\n",
    "    trainLen=int(0.8*len(IDs))#use 80% of the data as training set\n",
    "    valLen=int(0.1*len(IDs))\n",
    "    partition={}\n",
    "    partition['train'],partition['val'],partition['test']=IDs[0:trainLen],IDs[trainLen:trainLen+valLen],IDs[trainLen+valLen:]\n",
    "\n",
    "\n",
    "    #create ID lists for S, N wave test cases\n",
    "\n",
    "    inv_labels=[[],[]]\n",
    "    for ID in partition['test']:\n",
    "        inv_labels[labels[ID]].append(ID)\n",
    "\n",
    "    print('dataset contains '+str(Sctr)+' S waves and '+str(Nctr)+' noise waveforms.')\n",
    "    print('training set contains '+str(len(partition['train']))+' waveforms and test set contains '+str(len(partition['test']))+' waveforms.')\n",
    "    \n",
    "    return partition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset contains 14115 S waves and 13869 noise waveforms.\n",
      "training set contains 22387 waveforms and test set contains 2799 waveforms.\n",
      "dict_keys(['train', 'val', 'test'])\n"
     ]
    }
   ],
   "source": [
    "#wave_data_folder='/g/data/ha3/fxz547/seiswave_data_4ml'\n",
    "wave_data_folder='E:/Githubz/seiswave_data_4ml'\n",
    "\n",
    "ds_parts=build_input_data(wave_data_folder)\n",
    "\n",
    "print (ds_parts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset contains 14115 S waves and 13869 noise waveforms.\n",
      "training set contains 22387 waveforms and test set contains 2799 waveforms.\n",
      "['1776_S', '24049_S', '33438_S', '17198_S', '32385_S', '12547_S', '1938_S', '16143_S', '1045_S', '24837_S']\n",
      "['18363_N', '23520_N', '27817_N', '1334_N', '14605_N', '25427_N', '27651_N', '1083_N', '2842_N', '3770_N']\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "\n",
    "SIDs=data.getIDs(0)\n",
    "NIDs=data.getIDs(1)\n",
    "\n",
    "print (SIDs[:10])\n",
    "print(NIDs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npyfile = os.path.join(wave_data_folder,\"3996_S.npy\")\n",
    "my_waved= np.load(npyfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (type(my_waved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xar\n",
    "\n",
    "xa = xar.DataArray(my_waved, dims=['wamplitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xefaa400>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (wamplitude: 6000)>\n",
       "array([ 0.      , -0.006568, -0.011815, ...,  0.011536,  0.006559,  0.      ])\n",
       "Dimensions without coordinates: wamplitude"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Phase Using a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\miniconda3\\envs\\Keras224_tf13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\miniconda3\\envs\\Keras224_tf13\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Githubz\\passive-seismic\\seismic\\ml_classifier\\model.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  model = Model(input = inputs, output = dense5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99993563e-01   6.41166525e-06]]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/Githubz/seiswave_data_4ml\\\\1776_S.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-00ce48856a39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0moutfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'badS-N/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mtrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"PICKLE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"writing outfile\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<E:\\miniconda3\\envs\\Keras224_tf13\\lib\\site-packages\\decorator.py:decorator-gen-157>\u001b[0m in \u001b[0;36mread\u001b[1;34m(pathname_or_url, format, headonly, starttime, endtime, nearest_sample, dtype, apply_calib, check_compression, **kwargs)\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\Keras224_tf13\\lib\\site-packages\\obspy\\core\\util\\decorator.py\u001b[0m in \u001b[0;36m_map_example_filename\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_map_example_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\miniconda3\\envs\\Keras224_tf13\\lib\\site-packages\\obspy\\core\\stream.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(pathname_or_url, format, headonly, starttime, endtime, nearest_sample, dtype, apply_calib, check_compression, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No file matching file pattern: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No such file or directory\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[1;31m# Only raise error if no start/end time has been set. This\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m# will return an empty stream if the user chose a time window with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/Githubz/seiswave_data_4ml\\\\1776_S.pkl'"
     ]
    }
   ],
   "source": [
    "from model import shakenet\n",
    "#from data import *\n",
    "import data\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import obspy.core as oc\n",
    "\n",
    "model=shakenet(pretrained_weights='shakenet-model.hdf5')\n",
    "\n",
    "\n",
    "#dataDir='/g/data/ha3/rlt118/neural-datasets/categoriser-teleseismic/'\n",
    "dataDir= data.datafolder  #'/g/data/ha3/fxz547/seiswave_data_4ml'\n",
    "SIDs=data.getIDs(0)\n",
    "NIDs=data.getIDs(1)\n",
    "\n",
    "for ID in SIDs[:1]:\n",
    "    x=np.resize(np.load(os.path.join(dataDir,ID+'.npy')),(1,6002,1))\n",
    "    result=model.predict(x,batch_size=1)\n",
    "    \n",
    "    print (result)\n",
    "    \n",
    "    if np.argmax(result[0])==0:\n",
    "        outfname='correctS/'+ID+'.png'\n",
    "    else:\n",
    "        outfname='badS-N/'+ID+'.png'\n",
    "        \n",
    "    trc=oc.stream.read(os.path.join(dataDir,ID+'.pkl'),  format=\"PICKLE\")\n",
    "        \n",
    "    print(\"writing outfile\", outfname)\n",
    "    \n",
    "    trc.plot(outfile=outfname)\n",
    "\n",
    "for ID in NIDs[:1]:\n",
    "    x=np.resize(np.load(os.path.join(dataDir,ID+'.npy')),(1,6002,1))\n",
    "    result=model.predict(x,batch_size=1)\n",
    "    print (result)\n",
    "    \n",
    "    trc=oc.stream.read(os.path.join(dataDir,ID+'.pkl'), format=\"PICKLE\")\n",
    "    if np.argmax(result[0])==0:\n",
    "        outfname='badN-S/'+ID+'.png'\n",
    "    else:\n",
    "        outfname='correctN/'+ID+'.png'\n",
    "        \n",
    "    print(\"writing outfile\", outfname) \n",
    "    trc.plot(outfile=outfname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"Githubz\".\n"
     ]
    }
   ],
   "source": [
    "!dir 'E:/Githubz/seiswave_data_4ml\\\\1776_S.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
