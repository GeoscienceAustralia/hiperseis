#!/bin/bash
#PBS -P vy72
#PBS -N make_fed_asdf_index
#PBS -q normal
#PBS -l walltime=48:00:00,mem=32GB,ncpus=1,jobfs=256GB
#PBS -l storage=scratch/fxz547+gdata/ha3

#PBS -l wd
#PBS -j oe
#PBS -M fei.zhang@ga.gov.au
#PBS -m bae

module purge
module load pbs
module load python3-as-python
module load openmpi/3.1.4/
module load hdf5/1.10.5p

#export GDAL_DATA=/apps/gdal/3.0.2/share/gdal/
#export PYTHONPATH=/apps/gdal/3.0.2/lib64:/apps/gdal/3.0.2/lib64/python3.7/site-packages
export PYTHONPATH=/home/547/fxz547/github/hiperseis/:$PYTHONPATH
export PATH=$HOME/.local/bin:$PATH
export LC_ALL=en_AU.UTF-8
export LANG=en_AU.UTF-8


cd /home/547/fxz547/github/hiperseis/seismic/ASDFdatabase


python3 FederatedASDFDataSet.py /g/data/ha3/GASeisDataArchive/DevSpace/test_asdf_files.txt

# TODO: MPI requires HDF5/h5py to be complied with support for parallel I/O
# File "/home/547/fxz547/.local/lib/python3.7/site-packages/pyasdf/asdf_data_set.py", line 459, in mpi
#    raise RuntimeError(msg)
# RuntimeError: Running under MPI requires HDF5/h5py to be complied with support for parallel I/O
# mpirun -np $PBS_NCPUS python3 FederatedASDFDataSet.py /g/data/ha3/GASeisDataArchive/DevSpace/test_asdf_files.txt
