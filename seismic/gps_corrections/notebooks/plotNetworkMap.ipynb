{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot network location map based on ASDF database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath(os.path.abspath('../../..'))\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.ASDFdatabase import FederatedASDFDataSet\n",
    "from seismic.xcorqc.analytic_plot_utils import drawBBox\n",
    "import obspy\n",
    "from obspy.geodetics import locations2degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FederatedASDFDataSet.FederatedASDFDataSet(\"/g/data/ha3/Passive/SHARED_DATA/Index/asdf_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AU mainland lat/lon range\n",
    "au_min_lat, au_max_lat = -40, -10\n",
    "au_min_lon, au_max_lon = 110, 155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = ds.unique_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index from single level 'net.sta' format to two-level [net][sta] format.\n",
    "db_coords = defaultdict(dict)\n",
    "db_coords_str = defaultdict(dict)\n",
    "for fullcode, (lon, lat) in coords.items():\n",
    "    net, sta = fullcode.split('.')\n",
    "    start_time, end_time = ds.get_global_time_range(net, sta)\n",
    "    db_coords[net][sta] = (lat, lon, start_time, end_time)\n",
    "    db_coords_str[net][sta] = (lat, lon, str(start_time), str(end_time))\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('station_dict.json', 'w') as f:\n",
    "    json.dump(db_coords_str, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_mean_location(df, netcode):\n",
    "    \"\"\"\n",
    "    Get the mean station latitude and longitude coordinates for all stations in a given network.\n",
    "\n",
    "    :param df: Pandas dataframe\n",
    "    :type df: pandas.DataFrame\n",
    "    :param netcode: Network code for which mean coordinates will be returned\n",
    "    :type netcode: str\n",
    "    :return: Mean (latitude, longitude) coordinates of stations in the network\n",
    "    :rtype: tuple(float, float)\n",
    "    \"\"\"\n",
    "    mean_lat = df[df['net'] == netcode]['latitude'].mean()\n",
    "    mean_lon = df[df['net'] == netcode]['longitude'].mean()\n",
    "    return (mean_lat, mean_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some select stations require custom date filters to remove events outside\n",
    "# the known valid date range of a network. Filter out network codes from earlier\n",
    "# periods which are not of interest.\n",
    "def applyCustomerDateFilter(df):\n",
    "    DATE_FILTER = (\n",
    "        ('7D', pd.Timestamp(datetime.datetime(2010, 1, 1))),\n",
    "        ('7G', pd.Timestamp(datetime.datetime(2010, 1, 1))),\n",
    "    )\n",
    "    before = len(df)\n",
    "    for net, min_date in DATE_FILTER:\n",
    "        date_mask = (df['net'] == net) & (df['start_time'] < min_date.timestamp())\n",
    "        df = df[~date_mask]\n",
    "    after = len(df)\n",
    "    print('Removed {} stations due to known invalid timestamps'.format(before - after))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codes = [[net, sta, lat, lon, start_time, end_time] for net, st_db in db_coords.items()\n",
    "             for sta, (lat, lon, start_time, end_time) in st_db.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asdf = pd.DataFrame(np.array(all_codes), columns=['net', 'sta', 'lat', 'lon', 'start_time', 'end_time'])\n",
    "df_asdf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asdf = applyCustomerDateFilter(df_asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to fix date error in AQ metadata\n",
    "df_asdf.loc[df_asdf['net'] == 'AQ'].sort_values('end_time', ascending=False).iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_asdf.loc[(df_asdf['net'] == 'AQ') & (df_asdf['sta'] == 'F7'), 'end_time'] = \\\n",
    "#     df_asdf.loc[(df_asdf['net'] == 'AQ') & (df_asdf['sta'] == 'AQT3'), 'end_time']\n",
    "df_asdf.loc[(df_asdf['net'] == 'AQ') & (df_asdf['sta'] == 'AQT3'), 'end_time'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hack to fix date error in AQ metadata\n",
    "df_asdf.loc[df_asdf['sta'] == 'F7', 'end_time'] = \\\n",
    "    df_asdf.loc[(df_asdf['net'] == 'AQ') & (df_asdf['sta'] == 'AQT3'), 'end_time'].values[0]\n",
    "df_asdf.loc[df_asdf['sta'] == 'F7', 'end_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'GE' in df_asdf['net'], 'IR' in df_asdf['net'], 'IU' in df_asdf['net'], 'S' in df_asdf['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basemap_stations(dest_map, labels, lat, lon, size=50, color='g', label_rotation=0, label_font_size=9):\n",
    "    sc_handle = dest_map.scatter(lon, lat, size, latlon=True, marker='v', c=color, edgecolor='none', alpha=0.8)\n",
    "    text_handles = []\n",
    "    for i, label in enumerate(labels):\n",
    "        a_handle = plt.annotate(label, xy=dest_map(lon[i] + 0.02, lat[i] - 0.1), fontsize=label_font_size,\n",
    "                                rotation=label_rotation)\n",
    "        text_handles.append(a_handle)\n",
    "    return sc_handle, text_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_basemap_networks(df, label_stations=True, title=None, show_inset=True, show_legend=True,\n",
    "                          label_rotation=0, label_font_size=9, marker_size=50, axis_labeling=[True, True, True, True]):\n",
    "    # axis_labeling order is [left, right, top, bottom]\n",
    "\n",
    "    # Large array station IDs\n",
    "    warramunga_array = ['WB0', 'WB1', 'WB10', 'WB2', 'WB3', 'WB4', 'WB5', 'WB6', 'WB7', 'WB8', 'WB9',\n",
    "                        'WC1', 'WC2', 'WC3', 'WC4', 'WR0', 'WR1', 'WR10', 'WR2', 'WR3', 'WR4', 'WR5',\n",
    "                        'WR6', 'WR7', 'WR8', 'WR9']\n",
    "    alice_array = ['AS01', 'AS02', 'AS03', 'AS04', 'AS05', 'AS06', 'AS07', 'AS08', 'AS09', 'AS10',\n",
    "                   'AS11', 'AS12', 'AS13', 'AS14', 'AS15', 'AS16', 'AS17', 'AS18', 'AS19', 'AS31']\n",
    "    pilbara_array = ['PSA00', 'PSAA1', 'PSAA2', 'PSAA3', 'PSAB1', 'PSAB2', 'PSAB3',\n",
    "                     'PSAC1', 'PSAC2', 'PSAC3', 'PSAD1', 'PSAD2', 'PSAD3']\n",
    "    \n",
    "    # Limit to mainland\n",
    "    mainland_mask = (df['lat'] >= au_min_lat) & (df['lat'] <= au_max_lat) & \\\n",
    "                    (df['lon'] >= au_min_lon) & (df['lon'] <= au_max_lon)\n",
    "    df = df.loc[mainland_mask]\n",
    "\n",
    "    min_lat, max_lat = df['lat'].min(), df['lat'].max()\n",
    "    min_lon, max_lon = df['lon'].min(), df['lon'].max()\n",
    "    assert not np.isnan(min_lat)\n",
    "    assert not np.isnan(max_lat)\n",
    "    assert not np.isnan(min_lon)\n",
    "    assert not np.isnan(max_lon)\n",
    "#     assert min_lat >= au_min_lat, min_lat\n",
    "#     assert min_lon >= au_min_lon, min_lon\n",
    "#     assert max_lat <= au_max_lat, max_lat\n",
    "#     assert max_lon <= au_max_lon, max_lon\n",
    "\n",
    "    # Plot stations of network\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "    latlon_margin = max(0.8, max((max_lat - min_lat)/10, (max_lon - min_lon)/10))\n",
    "    m = Basemap(llcrnrlon=min_lon - latlon_margin, llcrnrlat=min_lat - latlon_margin,\n",
    "                urcrnrlon=max_lon + latlon_margin, urcrnrlat=max_lat + latlon_margin,\n",
    "                projection='lcc', resolution='i',\n",
    "                lat_1=min_lat, lat_2=max_lat,\n",
    "                lat_0=(min_lat + max_lat) * 0.5, lon_0=(min_lon + max_lon) * 0.5)\n",
    "\n",
    "    m.drawcoastlines(color='#a0a0a0', linewidth=2, zorder=0)\n",
    "    state_border_color = \"#9090ff\"\n",
    "    m.drawstates(color=state_border_color, linewidth=1.5, zorder=0)\n",
    "\n",
    "    #draw grid\n",
    "    parallels = np.linspace(np.floor(min_lat) - 5, np.ceil(max_lat) + 5, \\\n",
    "                            int((np.ceil(max_lat) + 5) - (np.floor(min_lat) - 5)) + 1)\n",
    "    m.drawparallels(parallels, labels=[axis_labeling[0], axis_labeling[1], False, False], color=\"#a0a0a0\")\n",
    "    meridians = np.linspace(np.floor(min_lon) - 5, np.ceil(max_lon) + 5, \\\n",
    "                            int((np.ceil(max_lon) + 5) - (np.floor(min_lon) - 5)) + 1)\n",
    "    m.drawmeridians(meridians, labels=[False, False, axis_labeling[2], axis_labeling[3]], rotation=45, color=\"#a0a0a0\")\n",
    "    main_ax = fig.gca()\n",
    "\n",
    "    # plot stations\n",
    "    color_index = 0\n",
    "    legend_labels = []\n",
    "    handles = []\n",
    "    text_handles = []\n",
    "    for net, df_net in df.groupby('net'):\n",
    "        colcode = \"C{}\".format(color_index)\n",
    "        legend_labels.append(net)\n",
    "        if label_stations:\n",
    "            labels = df_net['sta']\n",
    "            labels_warra = labels.isin(warramunga_array)\n",
    "            if np.any(labels_warra):\n",
    "                first = np.argwhere(labels_warra)[0]\n",
    "                labels.loc[labels_warra] = ''\n",
    "                labels.iloc[first] = 'Warramunga\\nArray'\n",
    "            labels_alice = labels.isin(alice_array)\n",
    "            if np.any(labels_alice):\n",
    "                first = np.argwhere(labels_alice)[0]\n",
    "                labels.loc[labels_alice] = ''\n",
    "                labels.iloc[first] = 'Alice Springs\\nArray'\n",
    "            labels_pilbara = labels.isin(pilbara_array)\n",
    "            if np.any(labels_pilbara):\n",
    "                first = np.argwhere(labels_pilbara)[0]\n",
    "                labels.loc[labels_pilbara] = ''\n",
    "                labels.iloc[first] = 'Pilbara\\nArray'\n",
    "            labels = labels.values\n",
    "        else:\n",
    "            labels = []\n",
    "        sc_h, text_h = plot_basemap_stations(m, labels, df_net['lat'].values, \n",
    "                                             df_net['lon'].values, color=colcode,\n",
    "                                             size=marker_size,\n",
    "                                             label_rotation=label_rotation,\n",
    "                                             label_font_size=label_font_size)\n",
    "        handles.append(sc_h)\n",
    "        text_handles.extend(text_h)\n",
    "        color_index = (color_index + 1) % 10\n",
    "    if show_legend:\n",
    "        plt.legend(handles, legend_labels, title='Network code')\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize = 18, y=1.05)\n",
    "\n",
    "    # Draw inset of entire continent\n",
    "    if show_inset:\n",
    "        inset_ax = fig.add_axes([0.75, 0.77, 0.100, 0.100])\n",
    "        inset = Basemap(resolution='c', ax=inset_ax, projection='merc',\n",
    "                        lat_0=-20, lon_0=132,\n",
    "                        llcrnrlon=au_min_lon, llcrnrlat=au_min_lat,\n",
    "                        urcrnrlon=au_max_lon, urcrnrlat=au_max_lat)\n",
    "        inset.fillcontinents(color='lightgray')\n",
    "        inset.drawstates(color=state_border_color)\n",
    "        drawBBox(min_lon, min_lat, max_lon, max_lat, inset, fill='True', facecolor='#40404080',\n",
    "                 linestyle=':', edgecolor='#404040')\n",
    "\n",
    "    plt.sca(main_ax)\n",
    "    # Can be slow, so comment out for prototyping\n",
    "    adjust_text(text_handles, arrowprops=dict(arrowstyle='-', color='red'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Australian permanent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include records from GE, IU, etc...\n",
    "from seismic.gps_corrections.relative_tt_residuals_plotter import determine_alternate_matching_codes\n",
    "IRIS_AU_STATIONS_FILE = \"../AU_irisws-fedcatalog_20190305T012747Z.txt\"\n",
    "df_copy = df_asdf.copy()\n",
    "name_remap = {'lat': 'stationLat', 'lon': 'stationLon'}\n",
    "df_copy.rename(name_remap, inplace=True, axis='columns')\n",
    "# display(df_copy)\n",
    "other_nets, other_stats = determine_alternate_matching_codes(df_copy, IRIS_AU_STATIONS_FILE, 'AU')\n",
    "other_dict = {'net': list(other_nets), 'sta': list(other_stats)}\n",
    "extra_AU_stations_mask = df_asdf[list(other_dict)].isin(other_dict).all(axis=1)\n",
    "df_extra_stations = df_asdf.loc[extra_AU_stations_mask]\n",
    "display(df_extra_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "\n",
    "# Plot map\n",
    "mask_au = (df_asdf['net'] == 'AU')\n",
    "\n",
    "# include schools\n",
    "SIS_NET = 'S'\n",
    "mask_sis = (df_asdf['net'] == SIS_NET)\n",
    "SIS_CODES = sorted([c for c in df_asdf.loc[mask_sis, 'sta'].unique() if c[0:2] == 'AU'])\n",
    "mask_sis = (mask_sis & df_asdf['sta'].isin(SIS_CODES))\n",
    "df_AU = pd.concat([df_asdf.loc[(mask_au | mask_sis)], df_extra_stations], sort=False)\n",
    "\n",
    "m = plot_basemap_networks(df_AU, title=\"Australian permanent network\", show_inset=False,)\n",
    "m.drawmapscale(129, -37, 135, -25, 1000.0, barstyle='fancy', fillcolor2='#808080',\n",
    "               linecolor='#808080', yoffset=40*1000)\n",
    "\n",
    "plt.savefig(\"PERMANENT_deployments.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table of date ranges\n",
    "df_code_sorted = df_AU.sort_values(['net', 'sta'])\n",
    "with open('PERMANENT_date_ranges.html', 'w') as f:\n",
    "    df_code_sorted.to_html(f, columns=['net', 'sta', 'start_time', 'end_time'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian temporary network deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_deploys = ['7B', '7D', '7E', '7F', '7G', '7J', '7K', '7W', '7X', 'AQ', 'OA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NETS = {'net': temp_deploys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "\n",
    "for target_net in TARGET_NETS['net']:\n",
    "    df_net = df_asdf.loc[df_asdf['net'] == target_net]\n",
    "    if df_net.empty:\n",
    "        print(\"WARNING: No data for network {}, skipping!\".format(target_net))\n",
    "        continue\n",
    "#     assert not np.any(np.isnan(df_net['lat']))\n",
    "#     assert not np.any(np.isnan(df_net['lon']))\n",
    "    plot_basemap_networks(df_net, title=\"Deployment Name: {}\".format(target_net),\n",
    "                          show_legend=False, label_font_size=12, marker_size=80)\n",
    "    start_time = df_net['start_time'].min()\n",
    "    end_time = df_net['end_time'].max()\n",
    "    plt.text(0.01, 0.01, \"Deployment date range: {} -- {}\".format(start_time, end_time),\n",
    "             transform=plt.gca().transAxes, fontsize=12)\n",
    "    plt.savefig('{}_map.png'.format(target_net), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mask = df_asdf[list(TARGET_NETS)].isin(TARGET_NETS).all(axis=1)\n",
    "df_target = df_asdf.loc[target_mask]\n",
    "\n",
    "plot_basemap_networks(df_target, title=\"Temporary Deployments\", show_inset=False, \n",
    "                      label_stations=False)\n",
    "plt.savefig(\"TEMP_deployments.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_time_overlapping(df, netcode, statcode, num=1, full_overlap=False):\n",
    "    # Find nearest num stations to netcode.statcode in df which are themselves\n",
    "    # not part of network netcode, and whose station dates overlap.\n",
    "    not_target_mask = (df['net'] != netcode)\n",
    "    target_mask = (df['net'] == netcode) & (df['sta'] == statcode)\n",
    "    target_lat, target_lon = df.loc[target_mask, ['lat', 'lon']].values[0]\n",
    "    start_time, end_time = df.loc[target_mask, ['start_time', 'end_time']].values[0]\n",
    "    if full_overlap:\n",
    "        time_mask = (df['start_time'] <= start_time) & (df['end_time'] >= end_time)\n",
    "    else:\n",
    "        time_mask = ((df['start_time'] <= end_time) & (df['end_time'] >= start_time))\n",
    "    df_filt = df.loc[not_target_mask & time_mask]\n",
    "    if df_filt.empty:\n",
    "        return pd.DataFrame()\n",
    "    # Distance is in degrees\n",
    "    df_filt['distance'] = df_filt.apply(lambda r: locations2degrees(\n",
    "        target_lat, target_lon, r['lat'], r['lon']), axis=1)\n",
    "    df_sorted = df_filt.sort_values('distance')\n",
    "    return df_sorted.iloc[0:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_net in TARGET_NETS['net']:\n",
    "    df_net = df_asdf.loc[df_asdf['net'] == target_net]\n",
    "    nearest = []\n",
    "    for sta in df_net['sta']:\n",
    "        result = find_nearest_time_overlapping(df_asdf, target_net, sta, num=20)\n",
    "        if result.empty:\n",
    "            continue\n",
    "        nearest.append(result)\n",
    "    if len(nearest) == 0:\n",
    "        print(\"WARNING: No results for network {}!\".format(target_net))\n",
    "        continue\n",
    "    nearest = pd.concat(nearest, sort=False).sort_values('distance')\n",
    "    nearest = nearest.loc[~nearest['net'].isin(temp_deploys)]\n",
    "    # drop_duplicates keeps first record, so 'distance' field will be the shortest\n",
    "    # distance to some station in the network.\n",
    "    nearest.drop_duplicates(['net', 'sta'], inplace=True)\n",
    "    print(\"Nearest overlapping neighbours for network {}:\".format(target_net))\n",
    "    display(nearest.iloc[0:10])\n",
    "    nearest.to_csv('{}_REF_neighbours.csv'.format(target_net), index=False, encoding='utf-8')\n",
    "\n",
    "    # Combine temp network records with candidate reference stations for plotting to map.\n",
    "    df_combined = pd.concat([df_net, nearest], sort=False)\n",
    "    plot_basemap_networks(df_combined, title=\"Deployment Name: {}\".format(target_net))\n",
    "    start_time = df_net['start_time'].min()\n",
    "    end_time = df_net['end_time'].max()\n",
    "    plt.text(0.01, 0.01, \"Deployment date range: {} -- {}\".format(start_time, end_time),\n",
    "             transform=plt.gca().transAxes, fontsize=12)\n",
    "    plt.savefig('{}_REF_neighbours.png'.format(target_net), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export station metadata for AU and temporary deployments to CSV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_au = df_asdf[df_asdf['net'] == 'AU'].sort_values('sta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_au.to_csv('AU_station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in temp_deploys:\n",
    "    csv_file = net + '_station_metadata.csv'\n",
    "    df_net = df_asdf[df_asdf['net'] == net].sort_values('sta')\n",
    "    df_net.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
