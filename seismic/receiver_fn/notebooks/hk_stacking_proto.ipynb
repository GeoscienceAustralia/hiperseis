{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import rf\n",
    "import rf.imaging\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import moment\n",
    "from scipy.interpolate import interp1d\n",
    "import obspy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in interactive widgets capability. See https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = r\"..\\DATA\\OA_event_waveforms_for_rf_20170911T000036-20181128T230620_LQT_td_rev3_qual.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oa_all = rf.read_rf(src_file, format='h5', group='/waveforms/OA.BT23.0M')\n",
    "oa_all = rf.read_rf(src_file, format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# oa_copy = copy.deepcopy(oa_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oa_copy.moveout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,9))\n",
    "# time_offset = oa_all[0].stats.onset - oa_all[0].stats.starttime\n",
    "# plt.plot(oa_all[0].times() - time_offset, oa_all[0].data)\n",
    "# time_offset = oa_copy[0].stats.onset - oa_copy[0].stats.starttime\n",
    "# plt.plot(oa_copy[0].times() - time_offset, oa_copy[0].data, '--')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define useful internal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_to_dict(rf_data):\n",
    "    db = defaultdict(lambda: defaultdict(list))\n",
    "    for s in rf_data:\n",
    "        _, sta, _, cha = s.id.split('.')\n",
    "        db[sta][cha].append(s)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_station_rf_overlays(db_station, title=None):\n",
    "    num_channels = 0\n",
    "    for ch, traces in db_station.items():\n",
    "        if traces:\n",
    "            num_channels += 1\n",
    "\n",
    "    plt.figure(figsize=(16, 8*num_channels))\n",
    "    colors = [\"#8080a040\", \"#80a08040\", \"#a0808040\"]\n",
    "    min_x = 1e+20\n",
    "    max_x = -1e20\n",
    "\n",
    "    signal_means = []\n",
    "    for i, (ch, traces) in enumerate(db_station.items()):\n",
    "        if not traces:\n",
    "            continue\n",
    "        col = colors[i]\n",
    "        plt.subplot(num_channels, 1, i + 1)\n",
    "        sta = traces[0].stats.station\n",
    "        for j, tr in enumerate(traces):\n",
    "            lead_time = tr.stats.onset - tr.stats.starttime\n",
    "            times = tr.times()\n",
    "            plt.plot(times - lead_time, tr.data, '--', color=col, linewidth=2)\n",
    "            mask = (~np.isnan(tr.data) & ~np.isinf(tr.data))\n",
    "            if j == 0:\n",
    "                data_mean = np.zeros_like(tr.data)\n",
    "                data_mean[mask] = tr.data[mask]\n",
    "                counts = mask.astype(np.float)\n",
    "            else:\n",
    "                data_mean[mask] += tr.data[mask]\n",
    "                counts += mask.astype(np.float)\n",
    "            # end if\n",
    "        # end for\n",
    "        data_mean = data_mean/counts\n",
    "        data_mean[(counts == 0)] = np.nan\n",
    "        signal_means.append(data_mean)\n",
    "        plt.plot(tr.times() - lead_time, data_mean, color=\"#202020\", linewidth=2)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude (normalized)')\n",
    "        plt.grid(linestyle=':', color=\"#80808020\")\n",
    "        title_text = '.'.join([sta, ch])\n",
    "        if title is not None:\n",
    "            title_text += ' ' + title\n",
    "        plt.title(title_text, fontsize=14)\n",
    "        x_lims = plt.xlim()\n",
    "        min_x = min(min_x, x_lims[0])\n",
    "        max_x = max(max_x, x_lims[1])\n",
    "    # end for\n",
    "    for i in range(num_channels):\n",
    "        subfig = plt.subplot(num_channels, 1, i + 1)\n",
    "        subfig.set_xlim((min_x, max_x))\n",
    "    # end for\n",
    "    \n",
    "    return signal_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_nth_root(arr, order):\n",
    "    if order == 1:\n",
    "        return arr\n",
    "    else:\n",
    "        return np.sign(arr)*np.power(np.abs(arr), 1.0/order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_nth_power(arr, order):\n",
    "    if order == 1:\n",
    "        return arr\n",
    "    else:\n",
    "        return np.sign(arr)*np.power(np.abs(arr), order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hk_stack(db_station, cha, h_range=np.linspace(10.0, 70.0, 301), k_range = np.linspace(1.3, 2.1, 201),\n",
    "                     V_p = 6.4, root_order=1, include_t3=True):\n",
    "\n",
    "    # Pre-compute grid quantities\n",
    "    k_grid, h_grid = np.meshgrid(k_range, h_range)\n",
    "    hk_stack = np.zeros_like(k_grid)\n",
    "    H_on_V_p = h_grid/V_p\n",
    "    k2 = k_grid*k_grid\n",
    "\n",
    "    stream_stack = []\n",
    "    cha_data = db_station[cha]\n",
    "    # Loop over streams, compute times, and stack interpolated values at those times\n",
    "    for s in cha_data:\n",
    "        incidence = s.stats.inclination\n",
    "        incidence_rad = incidence*np.pi/180.0\n",
    "        cos_i, sin_i = np.cos(incidence_rad), np.sin(incidence_rad)\n",
    "        sin2_i = sin_i*sin_i\n",
    "        term1 = H_on_V_p*k_grid*np.abs(cos_i)\n",
    "        term2 = H_on_V_p*np.sqrt(1 - k2*sin2_i)\n",
    "        # Time for Ps\n",
    "        t1 = term1 - term2\n",
    "        # Time for PpPs\n",
    "        t2 = term1 + term2\n",
    "        if include_t3:\n",
    "            # Time for PpSs + PsPs\n",
    "            t3 = 2*term1\n",
    "\n",
    "        # Subtract lead time so that primary P-wave arrival is at time zero.\n",
    "        lead_time = s.stats.onset - s.stats.starttime\n",
    "        times = s.times() - lead_time\n",
    "        # Create interpolator from stream signal for accurate time sampling.\n",
    "        interpolator = interp1d(times, s.data, kind='linear', copy=False, bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        phase_sum = []\n",
    "        phase_sum.append(signed_nth_root(interpolator(t1), root_order))\n",
    "        phase_sum.append(signed_nth_root(interpolator(t2), root_order))\n",
    "        if include_t3:\n",
    "            # Negative sign on the third term is intentional, see Chen et al. (2010) and Zhu & Kanamori (2000).\n",
    "            # It needs to be negative because the PpSs + PsPs peak has negative phase,\n",
    "            # see http://eqseis.geosc.psu.edu/~cammon/HTML/RftnDocs/rftn01.html\n",
    "            # Apply nth root technique to reduce uncorrelated noise (Chen et al. (2010))\n",
    "            phase_sum.append(-signed_nth_root(interpolator(t3), root_order))\n",
    "\n",
    "        stream_stack.append(phase_sum)\n",
    "    # end for\n",
    "\n",
    "    # Perform the stacking (sum) across streams. hk_stack retains separate t1, t2, and t3 components here.\n",
    "    hk_stack = np.nanmean(np.array(stream_stack), axis=0)\n",
    "\n",
    "    # This inversion of the nth root is different to Sippl and Chen, but consistent with Muirhead\n",
    "    # who proposed the nth root technique. It improves the contrast of the resulting plot.\n",
    "    if root_order != 1:\n",
    "        hk_stack = signed_nth_power(hk_stack, root_order)\n",
    "\n",
    "    return k_grid, h_grid, hk_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_stack(hk_components, weighting=(0.5, 0.5, 0.0)):\n",
    "    assert hk_components.shape[0] == len(weighting), hk_components.shape\n",
    "    hk_phase_stacked = np.dot(np.moveaxis(hk_components, 0, -1), np.array(weighting))\n",
    "    return hk_phase_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hk_stack(k_grid, h_grid, hk_stack, title=None, save_file=None, show=True, num=None, clip_negative=True):\n",
    "    # Call computed_weighted_stack() first to combine weighted components before calling this function.\n",
    "    # Use a perceptually linear color map.\n",
    "    colmap = 'plasma'\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    if clip_negative:\n",
    "        hk_stack[hk_stack < 0] = 0\n",
    "    plt.contourf(k_grid, h_grid, hk_stack, levels=50, cmap=colmap)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.set_ylabel('Stack sum')\n",
    "    plt.contour(k_grid, h_grid, hk_stack, levels=10, colors='k', linewidths=1)\n",
    "    plt.xlabel(r'$\\kappa = \\frac{V_p}{V_s}$ (ratio)', fontsize=14)\n",
    "    plt.ylabel('H = Moho depth (km)', fontsize=14)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    if num is not None:\n",
    "        xl = plt.xlim()\n",
    "        yl = plt.ylim()\n",
    "        txt_x = xl[0] + 0.85*(xl[1] - xl[0])\n",
    "        txt_y = yl[0] + 0.95*(yl[1] - yl[0])\n",
    "        plt.text(txt_x, txt_y, \"N = {}\".format(num), color=\"#ffffff\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    if save_file is not None:\n",
    "        tries = 10\n",
    "        while tries > 0:\n",
    "            try:\n",
    "                tries -= 1\n",
    "                plt.savefig(save_file, dpi=300)\n",
    "                break\n",
    "            except PermissionError:\n",
    "                time.sleep(1)\n",
    "                if tries == 0:\n",
    "                    print(\"WARNING: Failed to save file {} due to permissions!\".format(save_file))\n",
    "                    break\n",
    "            # end try\n",
    "        # end while\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_station_streams(db_station, freq_band=(None, None)):\n",
    "    \"\"\"Perform frequency filtering on streams. Returns a replica of db_station with streams containing filtered results.\n",
    "    \"\"\"\n",
    "    db_station_filt = defaultdict(list)\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        if ch == 'size' or i >= 3:\n",
    "            continue\n",
    "        for j, s in enumerate(streams):\n",
    "            stream_filt = s.copy()\n",
    "            if freq_band[0] is None and freq_band[1] is not None:\n",
    "                stream_filt.filter('lowpass', zerophase=True, corners=2, freq=freq_band[1])\n",
    "            elif freq_band[0] is not None and freq_band[1] is None:\n",
    "                stream_filt.filter('highpass', zerophase=True, corners=2, freq=freq_band[0])\n",
    "            elif freq_band[0] is not None and freq_band[1] is not None:\n",
    "                stream_filt.filter('bandpass', zerophase=True, corners=2, freqmin=freq_band[0],\n",
    "                                   freqmax=freq_band[1])\n",
    "            # end if\n",
    "            db_station_filt[ch].append(stream_filt)\n",
    "        # end for\n",
    "    # end for\n",
    "\n",
    "    return db_station_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def filter_station_to_mean_signal(db_station, min_correlation=1.0):\n",
    "    \"\"\"Filter out streams which are not 'close enough' to the mean signal,\n",
    "       based on simple correlation score.\n",
    "    \"\"\"\n",
    "    # Compute mean signals of channels in station\n",
    "    mean_rfs = []\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        if ch == 'size' or i >= 3:\n",
    "            continue\n",
    "        for j, s in enumerate(streams):\n",
    "            if j == 0:\n",
    "                data_mean = copy.deepcopy(s.data)\n",
    "            else:\n",
    "                data_mean += s.data\n",
    "            # end if\n",
    "        # end for\n",
    "        data_mean /= np.max(data_mean)\n",
    "        mean_rfs.append(data_mean)\n",
    "    # end for\n",
    "\n",
    "    # Filter out signals that do not meet minimum coherence with mean signal for each channel\n",
    "    db_station_filt = defaultdict(list)\n",
    "\n",
    "    corrs = []\n",
    "    for i, (ch, streams) in enumerate(db_station.items()):\n",
    "        for j, s in enumerate(streams):\n",
    "            corr = np.dot(s.data, mean_rfs[i])/np.dot(mean_rfs[i], mean_rfs[i])\n",
    "            if corr >= min_correlation:\n",
    "                db_station_filt[ch].append(s)\n",
    "            corrs.append(corr)\n",
    "        # end for\n",
    "    # end for\n",
    "                \n",
    "    return db_station_filt, corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rf_stack(rf_stream, time_window=(-10.0, 25.0)):\n",
    "    _ = rf_stream.plot_rf(fillcolors=('#000000', '#a0a0a0'), trim=time_window, trace_height=0.2, stack_height=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_metadata(db_station):\n",
    "    for ch, traces in db_station.items():\n",
    "        for tr in traces:\n",
    "            rms_amp = np.sqrt(np.mean(np.square(tr.data)))\n",
    "            cplx_amp = np.abs(hilbert(tr.data))\n",
    "            mean_cplx_amp = np.mean(cplx_amp)\n",
    "            amp_20pc = np.percentile(cplx_amp, 20)\n",
    "            amp_80pc = np.percentile(cplx_amp, 80)\n",
    "            tr.stats.rms_amp = rms_amp\n",
    "            tr.stats.mean_cplx_amp = mean_cplx_amp\n",
    "            tr.stats.amp_20pc = amp_20pc\n",
    "            tr.stats.amp_80pc = amp_80pc\n",
    "        # end for\n",
    "    # end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RFStream to dict database for convenient iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = rf_to_dict(oa_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# sta_codes = list(db.keys())\n",
    "# sta_lat = [db[sta]['HHR'][0].stats.station_latitude for sta in sta_codes]\n",
    "# sta_lon = [db[sta]['HHR'][0].stats.station_longitude for sta in sta_codes]\n",
    "# df_OA_sta = pd.DataFrame.from_dict({'Station': sta_codes, 'Latitude': sta_lat, 'Longitude': sta_lon})\n",
    "# df_OA_sta.to_csv('OA_stations.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for north-south lines\n",
    "# for sta in ['BV21', 'BV28', 'BX20', 'BX28', 'BY20', 'BY28', 'CB20', 'CB28', 'CD21', 'CD28']:\n",
    "#     lat = db[sta]['HHR'][0].stats.station_latitude\n",
    "#     lon = db[sta]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}: ({} {})\".format(sta, lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for west-east lines\n",
    "# for sta in ['BU22', 'CI22', 'BS26', 'CE26', 'BS28', 'CF28']:\n",
    "#     lat = db[sta]['HHR'][0].stats.station_latitude\n",
    "#     lon = db[sta]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}: ({} {})\".format(sta, lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get coordinates of select stations for Andrew Clark\n",
    "# for i, sta_pair in enumerate([('BV21', 'CC28'), ('BX20', 'BX28'), ('BY20', 'BY28')]):\n",
    "#     if i == 0:\n",
    "#         # NE-->SW line\n",
    "#         lat0 = db[sta_pair[0]]['HHR'][0].stats.station_latitude + 0.1\n",
    "#         lon0 = db[sta_pair[0]]['HHR'][0].stats.station_longitude - 0.1\n",
    "#         lat1 = db[sta_pair[1]]['HHR'][0].stats.station_latitude - 0.1\n",
    "#         lon1 = db[sta_pair[1]]['HHR'][0].stats.station_longitude + 0.1\n",
    "#     else:\n",
    "#         # N-->S line\n",
    "#         lat0 = db[sta_pair[0]]['HHR'][0].stats.station_latitude + 0.1\n",
    "#         lon0 = db[sta_pair[0]]['HHR'][0].stats.station_longitude\n",
    "#         lat1 = db[sta_pair[1]]['HHR'][0].stats.station_latitude - 0.1\n",
    "#         lon1 = db[sta_pair[1]]['HHR'][0].stats.station_longitude\n",
    "#     print(\"{}-{}: --start-latlon {} {} --end-latlon {} {}\".format(sta_pair[0], sta_pair[1], lat0, lon0, lat1, lon1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select test station and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test = db['BT23']\n",
    "# oa_test = db['BS27']\n",
    "# oa_test = db['BZ20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'HHQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oa_test[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([np.any(np.isnan(tr.data)) for tr in oa_test[channel]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional statistics for discrimination between trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_new_metadata(oa_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine available metadata in each trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_test[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_test[channel][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test[channel][0].stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display ranges of metadata and quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_series(traces, field):\n",
    "    x = [tr.stats.get(field) for tr in traces]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata and quality data on all traces for the target channel\n",
    "snr = get_metadata_series(oa_test[channel], 'snr')\n",
    "entropy = get_metadata_series(oa_test[channel], 'entropy')\n",
    "coherence = get_metadata_series(oa_test[channel], 'max_coherence')\n",
    "distance = get_metadata_series(oa_test[channel], 'distance')\n",
    "inclination = get_metadata_series(oa_test[channel], 'inclination')\n",
    "magnitude = get_metadata_series(oa_test[channel], 'event_magnitude')\n",
    "depth = get_metadata_series(oa_test[channel], 'event_depth')\n",
    "amax = get_metadata_series(oa_test[channel], 'amax')\n",
    "amp_20pc = get_metadata_series(oa_test[channel], 'amp_20pc')\n",
    "amp_80pc = get_metadata_series(oa_test[channel], 'amp_80pc')\n",
    "mean_cplx_amp = get_metadata_series(oa_test[channel], 'mean_cplx_amp')\n",
    "rf_group = get_metadata_series(oa_test[channel], 'rf_group')\n",
    "rms_amp = get_metadata_series(oa_test[channel], 'rms_amp')\n",
    "# Replace no-group group IDs with '-1'\n",
    "rf_group = [g if g is not None else -1 for g in rf_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_array = [(snr, \"SNR\"), (entropy, \"Entropy\"), (coherence, \"Coherence\"), (distance, \"Distance\"),\n",
    "              (inclination, \"Inclination\"), (magnitude, \"Magnitude\"), (amax, \"Max amplitude\"), (amp_20pc, \"Amplitude 20th perc.\"),\n",
    "              (amp_80pc, \"Amplitude 80th perc.\"), (mean_cplx_amp, \"Mean amplitude\"), (rms_amp, \"RMS amplitude\"), (rf_group, \"Group ID\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(4,3,1)\n",
    "for i, (data, name) in enumerate(dist_array):\n",
    "    ax = plt.subplot(4, 3, i + 1)\n",
    "#     plt.hist(data, bins=20)\n",
    "    sns.distplot(data, bins=20, ax=ax)\n",
    "    plt.title(name + \" distribution\", y=0.88, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine co-plots to look for discriminating variables\n",
    "df = pd.DataFrame.from_dict({\"SNR\": snr, \"Entropy\": entropy, \"Coherence\": coherence, \"Max_amp\": amax,\n",
    "                             \"Amp_20pc\": amp_20pc, \"Amp_80pc\": amp_80pc, \"RMS_amp\": rms_amp, \"Mean_amp\": mean_cplx_amp,\n",
    "                             \"Magnitude\": \">=6\", \"Distance\": \">=60\", \"Depth\": \">=80km\",\n",
    "                             \"Inclination\": \">=20\", \"Group_id\": rf_group,\n",
    "                             \"Quality\": \"unknown\"})\n",
    "df.loc[(np.array(magnitude) < 6.0), \"Magnitude\"] = \"<6\"\n",
    "df.loc[(np.array(distance) < 60.0), \"Distance\"] = \"<60\"\n",
    "df.loc[(np.array(inclination) < 20.0), \"Inclination\"] = \"<20\"\n",
    "df.loc[(np.array(depth) < 80.0), \"Depth\"] = \"<80km\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interactive widget to manually label the quality of the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rf_stack(rf.RFStream(oa_test[channel][0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot labelled data to find metrics to discriminate trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact_manual\n",
    "# def metrics_pairplot(hue_by=['Quality', 'Magnitude', 'Distance', 'Depth', 'Inclination', 'Group_id']):\n",
    "sns.pairplot(df, hue='Group_id', vars=[\"SNR\", \"Entropy\", \"Coherence\", \"Max_amp\", \"Amp_20pc\", \"Amp_80pc\", \"RMS_amp\", \"Mean_amp\"])\n",
    "plt.suptitle(\"Pairwise quality metrics scatter plot\", y=1.01, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RFs for traces filtered by various quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.snr >= 3.0]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.snr <= 0.8]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.entropy <= 3.0]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.entropy >= 4.2]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.max_coherence >= 0.3]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.max_coherence <= 0.02]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.event_magnitude >= 5.5 and tr.stats.snr >= 3]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "rf_stream_copy = copy.deepcopy(rf_stream)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.event_magnitude <= 5.5 and tr.stats.snr >= 3]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cherry pick the good stuff above from high mag plot and examine which metadata/quality params correspond to the good ones\n",
    "bad = list(50 - np.array([0, 1, 2, 3, 4, 5, 6, 7, 8 , 9, 10, 11, 12, 16, 17, 18, 20, 33, 37, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50]))\n",
    "good = list(50 - np.array([13, 14, 15, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 40 , 43]))\n",
    "rf_stream_bad = rf.RFStream([tr for i, tr in enumerate(rf_stream_copy) if i in bad])\n",
    "rf_stream_good = rf.RFStream([tr for i, tr in enumerate(rf_stream_copy) if i in good])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rf_stack(rf_stream_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rf_stack(rf_stream_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine metrics of good and bad group\n",
    "snr_good = [tr.stats.snr for tr in rf_stream_good]\n",
    "ent_good = [tr.stats.entropy for tr in rf_stream_good]\n",
    "mag_good = [tr.stats.event_magnitude for tr in rf_stream_good]\n",
    "snr_bad = [tr.stats.snr for tr in rf_stream_bad]\n",
    "ent_bad = [tr.stats.entropy for tr in rf_stream_bad]\n",
    "mag_bad = [tr.stats.event_magnitude for tr in rf_stream_bad]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sb.jointplot(snr_good, ent_good)\n",
    "plt.scatter(snr_good, ent_good, s=(np.array(mag_good)-5.0)*50, marker='o', alpha=0.5)\n",
    "plt.scatter(snr_bad, ent_bad, s=(np.array(mag_bad)-5.0)*50, marker='^', alpha=0.5)\n",
    "plt.grid(color=\"#80808080\", linestyle=':')\n",
    "plt.xlabel('SNR', fontsize=12)\n",
    "plt.ylabel('Entropy', fontsize=12)\n",
    "plt.title(\"Scatter plot of entropy vs SNR for good vs bad traces\")\n",
    "plt.legend(['Good', 'Bad'])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(snr_good, bins=20, alpha=0.5)\n",
    "plt.hist(snr_bad, bins=20, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(ent_good, bins=20, alpha=0.5)\n",
    "plt.hist(ent_bad, bins=20, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_good = [tr.stats.max_coherence for tr in rf_stream_good]\n",
    "coherence_bad = [tr.stats.max_coherence for tr in rf_stream_bad]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(snr_good, coherence_good, s=(np.array(mag_good)-5.0)*50, marker='o', alpha=0.5)\n",
    "plt.scatter(snr_bad, coherence_bad, s=(np.array(mag_bad)-5.0)*50, marker='^', alpha=0.5)\n",
    "plt.grid(color=\"#80808080\", linestyle=':')\n",
    "plt.xlabel('SNR', fontsize=12)\n",
    "plt.ylabel('Coherence', fontsize=12)\n",
    "plt.title(\"Scatter plot of coherence vs SNR for good vs bad traces\")\n",
    "plt.legend(['Good', 'Bad'])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(coherence_good, bins=20, alpha=0.5)\n",
    "plt.hist(coherence_bad, bins=20, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for new metrics to differentiate traces: mean and histogram moments of complex amplitude\n",
    "mean_rms_good =  [np.sqrt(np.mean(np.square(tr.data))) for tr in rf_stream_good]\n",
    "mean_rms_bad =  [np.sqrt(np.mean(np.square(tr.data))) for tr in rf_stream_bad]\n",
    "mean_amp_good =  [np.mean(np.abs(hilbert(tr.data))) for tr in rf_stream_good]\n",
    "mean_amp_bad =  [np.mean(np.abs(hilbert(tr.data))) for tr in rf_stream_bad]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(mean_rms_good, mean_amp_good, s=(np.array(mag_good)-5.0)*50, marker='o', alpha=0.5)\n",
    "plt.scatter(mean_rms_bad, mean_amp_bad, s=(np.array(mag_bad)-5.0)*50, marker='^', alpha=0.5)\n",
    "plt.grid(color=\"#80808080\", linestyle=':')\n",
    "plt.xlabel('Mean RMS real amplitude', fontsize=12)\n",
    "plt.ylabel('Mean complex amplitude', fontsize=12)\n",
    "plt.title(\"Scatter plot of mean complex amplitude vs RMS amplitude for good vs bad traces\")\n",
    "plt.legend(['Good', 'Bad'])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mean_rms_good, bins=20, alpha=0.5)\n",
    "plt.hist(mean_rms_bad, bins=20, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(mean_amp_good, bins=20, alpha=0.5)\n",
    "plt.hist(mean_amp_bad, bins=20, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot overlay of all traces in test channel (no filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traces = len(oa_test[channel])\n",
    "trace_mean = plot_station_rf_overlays(oa_test, '(all {} traces)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split traces into groups and plot each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict = {}\n",
    "for tr in oa_test[channel]:\n",
    "    grp = tr.stats.get('rf_group')\n",
    "    if grp is not None:\n",
    "        if grp in group_dict:\n",
    "            group_dict[grp][channel].append(tr)\n",
    "        else:\n",
    "            group_dict[grp] = {}\n",
    "            group_dict[grp][channel] = [tr]\n",
    "\n",
    "groups = group_dict.keys()\n",
    "print(\"Found {} groups: {}\".format(len(groups), groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp_id, group in group_dict.items():\n",
    "    num_traces = len(group[channel])\n",
    "    title = '(group {}, {} traces)'.format(grp_id, num_traces)\n",
    "    group_mean = plot_station_rf_overlays(group, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot only traces with similarity to the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test_filt, corrs = filter_station_to_mean_signal(oa_test, min_correlation=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corrs, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traces = len(oa_test_filt[channel])\n",
    "test_filt_mean = plot_station_rf_overlays(oa_test_filt, '({} traces similar to mean)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the effectiveness of phase-weighting the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.receiver_fn.rf_util import phase_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = phase_weights(oa_test_filt[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = oa_test_filt[channel][0]\n",
    "time_offset = s0.stats.onset - s0.stats.starttime\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, pw)\n",
    "plt.title('Phase weightings')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate effect of phase weighting to suppress areas where phases tend to be random.\n",
    "pw_exponent = 2\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, s0.data, linewidth=2)\n",
    "plt.plot(s0.times() - time_offset, s0.data*pw**pw_exponent, '--', linewidth=2)\n",
    "plt.legend(['Original', 'Phase weighted'])\n",
    "plt.title('Phase weighting applied to a single trace')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate effect of phase weighting applied to entire station data\n",
    "# NOTE: This will overwrite the original filtered data\n",
    "for tr in oa_test_filt[channel]:\n",
    "    tr.data = tr.data*pw**pw_exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traces = len(oa_test_filt[channel])\n",
    "test_filt_mean = plot_station_rf_overlays(oa_test_filt, '({} traces similar to mean, phase weighted)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot HK stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stack\n",
    "weighting = (0.7, 0.2, 0.1)\n",
    "\n",
    "for cha in [channel]:\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(oa_test, cha, root_order=2)\n",
    "\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "    \n",
    "    sta = oa_test[cha][0].stats.station\n",
    "\n",
    "    num = len(oa_test[cha])\n",
    "    save_file = None\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[0], title=sta + '.{} Ps'.format(cha), num=num)\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack[1], title=sta + '.{} PpPs'.format(cha), num=num)\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack[2], title=sta + '.{} PpSs + PsPs'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha) + ' (no filtering)', num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stack for filtered data\n",
    "weighting = (0.7, 0.2, 0.1)\n",
    "for cha in [channel]:\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(oa_test_filt, cha, root_order=2)\n",
    "\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "\n",
    "    sta = oa_test_filt[cha][0].stats.station\n",
    "\n",
    "    num = len(oa_test_filt[cha])\n",
    "    save_file = None\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[0], title=sta + '.{} Ps'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[1], title=sta + '.{} PpPs'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha) + \" (filtered + phase weighted)\", num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over all OA stations and plot HK-stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha = channel\n",
    "pbar = tqdm(total=len(db))\n",
    "show = False\n",
    "weighting = (0.5, 0.4, 0.1)\n",
    "for sta, db_sta in db.items():\n",
    "    pbar.set_description(sta)\n",
    "    pbar.update()\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(db_sta, cha, root_order=2)\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "    sta = db_sta[cha][0].stats.station\n",
    "    save_file = sta + \"_{}_hk_stack.png\".format(cha)\n",
    "    num = len(db_sta[cha])\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha), save_file=save_file, show=show, num=num)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of group ID distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for sta, db_sta in db.items():\n",
    "    ch_data = db_sta[channel]\n",
    "    for s in ch_data:\n",
    "        grp = s.stats.get('rf_group')\n",
    "        if grp is not None:\n",
    "            groups.append(s.stats.rf_group)\n",
    "print(min(groups), max(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(groups, bins=20)\n",
    "plt.xticks(range(max(groups) + 1))\n",
    "plt.xlabel('Group ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of inclinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incs = []\n",
    "for sta, db_sta in db.items():\n",
    "    ch_data = db_sta[channel]\n",
    "    for s in ch_data:\n",
    "        incs.append(s.stats.inclination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(incs, bins=20)\n",
    "plt.xlabel('Inclination (deg)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
