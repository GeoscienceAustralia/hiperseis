{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from collections import defaultdict\n",
    "# import time\n",
    "\n",
    "import numpy as np\n",
    "import rf\n",
    "import rf.imaging\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import moment\n",
    "# from scipy.interpolate import interp1d\n",
    "import obspy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in interactive widgets capability. See https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismic.receiver_fn.rf_util as rf_util\n",
    "import seismic.receiver_fn.rf_plot_utils as rf_plot_utils\n",
    "import seismic.receiver_fn.rf_stacking as rf_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = r\"..\\DATA\\OA_event_waveforms_for_rf_20170911T000036-20181128T230620_LQT_td_rev3_qual.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_all = rf_util.read_h5_rf(src_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RFStream to dict database for convenient iteration and addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = rf_util.rf_to_dict(oa_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select test station and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station = 'BT23'\n",
    "# test_station = 'BS27'\n",
    "# test_station = 'BZ20'\n",
    "oa_test = db[test_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'HHQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(oa_test[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any traces with NaNs in them. RF quality filtering prior to this SHOULD have removed any such traces.\n",
    "np.sum([np.any(np.isnan(tr.data)) for tr in oa_test[channel]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional statistics for prediction of trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_util.compute_extra_rf_stats(oa_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine available metadata in each trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_test[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(oa_test[channel][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_test[channel][0].stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display ranges of metadata and quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_series(traces, field):\n",
    "    x = [tr.stats.get(field) for tr in traces]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metadata and quality data on all traces for the target channel\n",
    "snr = get_metadata_series(oa_test[channel], 'snr')\n",
    "entropy = get_metadata_series(oa_test[channel], 'entropy')\n",
    "coherence = get_metadata_series(oa_test[channel], 'max_coherence')\n",
    "distance = get_metadata_series(oa_test[channel], 'distance')\n",
    "inclination = get_metadata_series(oa_test[channel], 'inclination')\n",
    "magnitude = get_metadata_series(oa_test[channel], 'event_magnitude')\n",
    "depth = get_metadata_series(oa_test[channel], 'event_depth')\n",
    "amax = get_metadata_series(oa_test[channel], 'amax')\n",
    "amp_20pc = get_metadata_series(oa_test[channel], 'amp_20pc')\n",
    "amp_80pc = get_metadata_series(oa_test[channel], 'amp_80pc')\n",
    "mean_cplx_amp = get_metadata_series(oa_test[channel], 'mean_cplx_amp')\n",
    "rf_group = get_metadata_series(oa_test[channel], 'rf_group')\n",
    "rms_amp = get_metadata_series(oa_test[channel], 'rms_amp')\n",
    "# Replace no-group group IDs with '-1'\n",
    "rf_group = [g if g is not None else -1 for g in rf_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_array = [(snr, \"SNR\"), (entropy, \"Entropy\"), (coherence, \"Coherence\"), (distance, \"Distance\"),\n",
    "              (inclination, \"Inclination\"), (magnitude, \"Magnitude\"), (amax, \"Max amplitude\"), (amp_20pc, \"Amplitude 20th perc.\"),\n",
    "              (amp_80pc, \"Amplitude 80th perc.\"), (mean_cplx_amp, \"Mean amplitude\"), (rms_amp, \"RMS amplitude\"), (rf_group, \"Group ID\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(4,3,1)\n",
    "for i, (data, name) in enumerate(dist_array):\n",
    "    ax = plt.subplot(4, 3, i + 1)\n",
    "#     plt.hist(data, bins=20)\n",
    "    sns.distplot(data, bins=20, ax=ax)\n",
    "    plt.title(name + \" distribution\", y=0.88, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine co-plots to look for discriminating variables\n",
    "df = pd.DataFrame.from_dict({\"SNR\": snr, \"Entropy\": entropy, \"Coherence\": coherence, \"Max_amp\": amax,\n",
    "                             \"Amp_20pc\": amp_20pc, \"Amp_80pc\": amp_80pc, \"RMS_amp\": rms_amp, \"Mean_amp\": mean_cplx_amp,\n",
    "                             \"Magnitude\": \">=6\", \"Distance\": \">=60\", \"Depth\": \">=80km\",\n",
    "                             \"Inclination\": \">=20\", \"Group_id\": rf_group,\n",
    "                             \"Quality\": \"unknown\"})\n",
    "df.loc[(np.array(magnitude) < 6.0), \"Magnitude\"] = \"<6\"\n",
    "df.loc[(np.array(distance) < 60.0), \"Distance\"] = \"<60\"\n",
    "df.loc[(np.array(inclination) < 20.0), \"Inclination\"] = \"<20\"\n",
    "df.loc[(np.array(depth) < 80.0), \"Depth\"] = \"<80km\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_file = test_station + \"_quality.csv\"\n",
    "if os.path.isfile(qual_file):\n",
    "    loaded_quality = pd.read_csv(qual_file, index_col=0, header=None)\n",
    "    df['Quality'] = loaded_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interactive widget to manually label the quality of the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quality guide:\")\n",
    "print(\"'a' = low signal before onset, higher signal after onset with some multiples visible\")\n",
    "print(\"'b' = signal similar before and after onset, cannot make out multiples with much confidence\")\n",
    "print(\"Create labels by entering 10 character string of 'a's and 'b's according to quality, ordered from bottom to top trace.\")\n",
    "# Create labels for quality. Note that rf plots are numbered from the bottom up, whereas the Pandas table is displayed ordered from the top down.\n",
    "quality_updated = False\n",
    "for i in range(0, len(df), 10):\n",
    "    existing_qual = df['Quality'].iloc[i:i+10].values\n",
    "    if not 'unknown' in existing_qual:\n",
    "        continue\n",
    "    rf_slice = rf.RFStream(oa_test[channel][i:i+10])\n",
    "    plot_rf_stack(rf_slice, trace_height=0.4)\n",
    "    plt.show()\n",
    "    get_labels = ''\n",
    "    quit = False\n",
    "    while len(get_labels) != len(rf_slice):\n",
    "        get_labels = input(\"Enter labels: \")\n",
    "        if get_labels.lower() == 'quit':\n",
    "            quit = True\n",
    "            break\n",
    "        if len(get_labels) != len(rf_slice):\n",
    "            print(\"Wrong number of labels, try again!\")\n",
    "    if quit:\n",
    "        break\n",
    "    for j, qual in enumerate(get_labels):\n",
    "        df['Quality'].iloc[i+j] = qual\n",
    "    quality_updated = True\n",
    "    display(df.iloc[i:i+10])\n",
    "\n",
    "if quality_updated:\n",
    "    df['Quality'].to_csv(qual_file)\n",
    "else:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign quality category to trace metadata\n",
    "for i, tr in enumerate(oa_test[channel]):\n",
    "    tr.stats.quality = df['Quality'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot labelled data to find metrics to discriminate trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_metrics = [\"SNR\", \"Entropy\", \"Coherence\", \"Max_amp\", \"Amp_20pc\", \"Amp_80pc\", \"RMS_amp\", \"Mean_amp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual\n",
    "def metrics_pairplot(hue_by=['Quality', 'Magnitude', 'Distance', 'Depth', 'Inclination', 'Group_id']):\n",
    "    hue_order = None\n",
    "    if hue_by == 'Quality':\n",
    "        hue_order = ['unknown', 'b', 'a'] if 'unknown' in df['Quality'] else ['b', 'a']\n",
    "    sns.pairplot(df, hue=hue_by, hue_order=hue_order, vars=stats_metrics)\n",
    "    plt.suptitle(\"Pairwise quality metrics scatter plot\", y=1.01, fontsize=20)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how effective selected metadata metrics are at filtering to the Quality A set of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = len(oa_test[channel])\n",
    "\n",
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.quality == 'a']\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream_A = rf.RFStream(rf_data)\n",
    "print(\"Quality A: {} events\".format(len(rf_stream_A)))\n",
    "quality_A_ids = [tr.stats.event_id for tr in rf_stream_A]\n",
    "not_quality_A_ids = [tr.stats.event_id for tr in oa_test[channel] if tr.stats.event_id not in quality_A_ids]\n",
    "\n",
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.snr >= 1.5 and tr.stats.entropy >= 3.0 and tr.stats.max_coherence >= 0.15]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream_stats_filtered = rf.RFStream(rf_data)\n",
    "num_filtered = len(rf_stream_stats_filtered)\n",
    "print(\"Stats filtered: {} events\".format(num_filtered))\n",
    "stats_filtered_ids = [tr.stats.event_id for tr in rf_stream_stats_filtered]\n",
    "true_positives = [id for id in stats_filtered_ids if id in quality_A_ids]\n",
    "false_negatives = [id for id in quality_A_ids if id not in stats_filtered_ids]\n",
    "num_true_positive = len(true_positives)\n",
    "num_false_negative = len(false_negatives)\n",
    "num_predicted_positive = len(stats_filtered_ids)\n",
    "num_predicted_negative = num_total - num_predicted_positive\n",
    "\n",
    "# Determine how many of the events in stats_filtered_ids are Quality A events\n",
    "print(\"{}/{} correct filtered events (snr, entropy, coherence) (Positive predictive value = {:.2f}%, False omission rate = {:.2f}%)\"\n",
    "      .format(num_true_positive, num_filtered, 100.0*num_true_positive/num_predicted_positive, 100*num_false_negative/num_predicted_negative))\n",
    "\n",
    "# Repeat using amplitude metrics\n",
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.amax <= 0.3 and tr.stats.amp_20pc <= 0.03 and tr.stats.amp_80pc <= 0.1]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream_stats2_filtered = rf.RFStream(rf_data)\n",
    "num2_filtered = len(rf_stream_stats2_filtered)\n",
    "print(\"Stats2 filtered: {} events\".format(num2_filtered))\n",
    "stats2_filtered_ids = [tr.stats.event_id for tr in rf_stream_stats2_filtered]\n",
    "true_positives = [id for id in stats2_filtered_ids if id in quality_A_ids]\n",
    "false_negatives = [id for id in quality_A_ids if id not in stats2_filtered_ids]\n",
    "num_true_positive = len(true_positives)\n",
    "num_false_negative = len(false_negatives)\n",
    "num_predicted_positive = len(stats2_filtered_ids)\n",
    "num_predicted_negative = num_total - num_predicted_positive\n",
    "\n",
    "print(\"{}/{} filtered events (Max. amp, 20%, 80%) are quality A events (Positive predictive value = {:.2f}%, False omission rate = {:.2f}%)\"\n",
    "      .format(num_true_positive, num2_filtered, 100.0*num_true_positive/num_predicted_positive, 100*num_false_negative/num_predicted_negative))\n",
    "\n",
    "# The performance stats shown below show what a human achieves trying to tune data selection criteria manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how well a neural network classifier works in comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use simple stats for feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, stats_metrics].values\n",
    "X[np.isnan(X)] = 0\n",
    "y = df['Quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_transformed = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This perceptron network has been simplified back to the bare bone so that it corresponds to a linear predictor,\n",
    "# as higher order complexity and non-linear activation functions gave no improvement in accuracy.\n",
    "clf_simple = MLPClassifier(solver='lbfgs', alpha=1e-4, max_iter=1000, activation='identity',\n",
    "                           hidden_layer_sizes=(1,), random_state=3772, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to tune hyperparameters\n",
    "scores = cross_val_score(clf_simple, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With tuned hyperparameters, train on full training set.\n",
    "clf_simple.fit(X_train, y_train)\n",
    "print(\"Final loss: %0.4f\" % clf_simple.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = clf_simple.score(X_test, y_test)\n",
    "print(\"Final accuracy: %0.3f\" % final_score)\n",
    "# We get decent performance with a trivial network (1 neuron) with trivial activation f(x) = x,\n",
    "# which means that simply a linear combination of feature vector is sufficient to determine\n",
    "# classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = clf_simple.predict(X_test)\n",
    "full_prediction = clf_simple.predict(X)\n",
    "df['Prediction'] = full_prediction\n",
    "df.sample(20, random_state=3772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats_metrics)\n",
    "print(clf_simple.coefs_[0].T[0])\n",
    "print(clf_simple.coefs_[1][0])\n",
    "print(clf_simple.intercepts_[0], clf_simple.intercepts_[1])\n",
    "A0 = clf_simple.coefs_[0].T[0]\n",
    "b0 = clf_simple.intercepts_[0][0]\n",
    "A1 = clf_simple.coefs_[1][0][0]\n",
    "b1 = clf_simple.intercepts_[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linear combination of features according to solver weightings, to check how to use these directly for class prediction.\n",
    "# Should give exact same result as MLPClassifier.\n",
    "lin_comb_prediction = A1*(np.matmul(X_test, A0) + b0) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame.from_dict({\"Truth\": y_test, \"MLP prediction\": test_prediction, \"Lin. predictor\": lin_comb_prediction})\n",
    "df_predictions['Lin. predictor'].loc[(lin_comb_prediction < 0)] = 'a'\n",
    "df_predictions['Lin. predictor'].loc[(lin_comb_prediction >= 0)] = 'b'\n",
    "assert np.all(df_predictions['Lin. predictor'] == df_predictions['MLP prediction'])\n",
    "df_predictions.sample(10, random_state=3772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix and verify how to compute accuracy from it.\n",
    "cm = confusion_matrix(df_predictions['Truth'], df_predictions['MLP prediction'], labels=['b', 'a'])\n",
    "print(cm)\n",
    "print(np.sum(cm))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm))/float(np.sum(cm))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how good is the DBSCAN grouping as an indicator of trace quality.\n",
    "dbscan_group = df['Group_id'].copy()\n",
    "primary_group_mask = (dbscan_group == 0)\n",
    "dbscan_group[primary_group_mask] = 'a'\n",
    "dbscan_group[~primary_group_mask] = 'b'\n",
    "cm_dbscan = confusion_matrix(df['Quality'], dbscan_group, labels=['b', 'a'])\n",
    "print(cm_dbscan)\n",
    "print(np.sum(cm_dbscan))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm_dbscan))/float(np.sum(cm_dbscan))))\n",
    "# Result here indicates DBSCAN grouping is not a strong predictor of subjective trace quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how good SNR alone is as an indicator of trace quality.\n",
    "snr_series = df['SNR'].copy()\n",
    "high_snr_mask = (snr_series >= 1.5)\n",
    "snr_series[high_snr_mask] = 'a'\n",
    "snr_series[~high_snr_mask] = 'b'\n",
    "cm_snr = confusion_matrix(df['Quality'], snr_series, labels=['b', 'a'])\n",
    "print(cm_snr)\n",
    "print(np.sum(cm_snr))\n",
    "print(\"Accuracy: %0.3f\" % (np.sum(np.diag(cm_snr))/float(np.sum(cm_snr))))\n",
    "# Result here indicates SNR alone is quite a good indicator of quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign PREDICTED quality category to trace metadata\n",
    "for i, tr in enumerate(oa_test[channel]):\n",
    "    tr.stats.predicted_quality = df['Prediction'].iloc[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use (-10, 25) trimmed waveform for feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_traces = rf.RFStream([tr for tr in oa_test[channel]])\n",
    "all_traces = all_traces.slice2(-10.0, 25.0, reftime='onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([tr.data for tr in all_traces])\n",
    "y = df['Quality'].values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert into frequency domain\n",
    "# _, X = signal.periodogram(X)\n",
    "# print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = MLPClassifier(solver='lbfgs', alpha=1e-4, max_iter=1000, activation='relu',\n",
    "                       hidden_layer_sizes=(20,), random_state=3772, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_rf, X_train_transformed, y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf.fit(X_train_transformed, y_train)\n",
    "print(\"Final loss: %0.4f\" % clf_rf.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = scaler.transform(X_test)\n",
    "final_score_rf = clf_rf.score(X_test_transformed, y_test)\n",
    "print(\"Final accuracy: %0.3f\" % final_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Support Vector Classifier instead to assess performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, stats_metrics].values\n",
    "X[np.isnan(X)] = 0\n",
    "y = df['Quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_transformed = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = LinearSVC(random_state=3772)\n",
    "# clf_svc = SVC(C=1.0, gamma='scale', kernel='rbf', random_state=3772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to tune hyperparameters\n",
    "scores = cross_val_score(clf_svc, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With tuned hyperparameters, train on full training set.\n",
    "clf_svc.fit(X_train, y_train)\n",
    "print(\"Final loss: %0.4f\" % clf_simple.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = clf_svc.score(X_test, y_test)\n",
    "print(\"Final accuracy: %0.3f\" % final_score)\n",
    "# This result is pretty much exactly same as above MLClassifier with one neuron, i.e. it's just a linear predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classification using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, stats_metrics].values\n",
    "X[np.isnan(X)] = 0\n",
    "y = df['Quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = tree.DecisionTreeClassifier(random_state=3772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation to tune hyperparameters\n",
    "scores = cross_val_score(clf_tree, X_train, y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RFs for traces filtered by various quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rf_stack(rf_stream_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.quality == 'b']\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.snr >= 3.0]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.snr <= 0.8]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.entropy >= 4.2]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.entropy <= 3.0]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.max_coherence >= 0.3]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.max_coherence <= 0.02]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.event_magnitude >= 5.5]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.event_magnitude < 5.5]\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Quality A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.predicted_quality == 'a']\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Quality B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = [tr for tr in oa_test[channel] if tr.stats.predicted_quality == 'b']\n",
    "rf_data = sorted(rf_data, key=lambda v: v.stats.back_azimuth)\n",
    "rf_stream = rf.RFStream(rf_data)\n",
    "plot_rf_stack(rf_stream[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot overlay of all traces in test channel (no filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_quality = {channel: [tr for tr in rf_stream_A]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traces = len(oa_quality[channel])\n",
    "trace_mean = rf_plot_utils.plot_station_rf_overlays(oa_quality, '(all {} traces)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split traces into groups and plot each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict = {}\n",
    "for tr in oa_quality[channel]:\n",
    "    grp = tr.stats.get('rf_group')\n",
    "    if grp is not None:\n",
    "        if grp in group_dict:\n",
    "            group_dict[grp][channel].append(tr)\n",
    "        else:\n",
    "            group_dict[grp] = {}\n",
    "            group_dict[grp][channel] = [tr]\n",
    "\n",
    "groups = group_dict.keys()\n",
    "print(\"Found {} groups: {}\".format(len(groups), groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp_id, group in group_dict.items():\n",
    "    num_traces = len(group[channel])\n",
    "    title = '(group {}, {} traces)'.format(grp_id, num_traces)\n",
    "    group_mean = rf_plot_utils.plot_station_rf_overlays(group, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot only traces with similarity to the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oa_quality_filt, corrs = filter_station_to_mean_signal(oa_quality, min_correlation=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(corrs, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traces = len(oa_quality_filt[channel])\n",
    "test_filt_mean = rf_plot_utils.plot_station_rf_overlays(oa_quality_filt, '({} traces similar to mean)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the effectiveness of phase-weighting the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seismic.receiver_fn.rf_util import phase_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = phase_weights(oa_quality_filt[channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = oa_quality_filt[channel][0]\n",
    "time_offset = s0.stats.onset - s0.stats.starttime\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, pw)\n",
    "plt.title('Phase weightings')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate effect of phase weighting to suppress areas where phases tend to be random.\n",
    "pw_exponent = 2\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(s0.times() - time_offset, s0.data, linewidth=2)\n",
    "plt.plot(s0.times() - time_offset, s0.data*pw**pw_exponent, '--', linewidth=2)\n",
    "plt.legend(['Original', 'Phase weighted'])\n",
    "plt.title('Phase weighting applied to a single trace')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply phase weighting to data for H-k stacking\n",
    "# # NOTE: This will overwrite the original filtered data\n",
    "# for tr in oa_quality_filt[channel]:\n",
    "#     tr.data = tr.data*pw**pw_exponent\n",
    "\n",
    "# num_traces = len(oa_quality_filt[channel])\n",
    "# test_filt_mean = rf_plot_utils.plot_station_rf_overlays(oa_quality_filt, '({} traces similar to mean, phase weighted)'.format(num_traces))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot HK stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_src_data = oa_quality_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stack\n",
    "weighting = (0.35, 0.35, 0.3)\n",
    "\n",
    "for cha in [channel]:\n",
    "    k_grid, h_grid, hk_stack = compute_hk_stack(hk_src_data, cha, root_order=2)\n",
    "\n",
    "    hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "    \n",
    "    sta = hk_src_data[cha][0].stats.station\n",
    "\n",
    "    num = len(hk_src_data[cha])\n",
    "    save_file = None\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[0], title=sta + '.{} Ps'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[1], title=sta + '.{} PpPs'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack[2], title=sta + '.{} PpSs + PsPs'.format(cha), num=num)\n",
    "    plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha) + ' (no filtering)', num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over all OA stations and plot HK-stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cha = channel\n",
    "# pbar = tqdm(total=len(db))\n",
    "# show = False\n",
    "# weighting = (0.5, 0.4, 0.1)\n",
    "# for sta, db_sta in db.items():\n",
    "#     pbar.set_description(sta)\n",
    "#     pbar.update()\n",
    "#     k_grid, h_grid, hk_stack = compute_hk_stack(db_sta, cha, root_order=2)\n",
    "#     hk_stack_sum = compute_weighted_stack(hk_stack, weighting)\n",
    "#     sta = db_sta[cha][0].stats.station\n",
    "#     save_file = sta + \"_{}_hk_stack.png\".format(cha)\n",
    "#     num = len(db_sta[cha])\n",
    "#     plot_hk_stack(k_grid, h_grid, hk_stack_sum, title=sta + '.{}'.format(cha), save_file=save_file, show=show, num=num)\n",
    "# pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
